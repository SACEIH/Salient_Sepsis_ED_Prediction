{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3c7567",
   "metadata": {},
   "source": [
    "# Identification of Best Model \n",
    "\n",
    "Clean up code and emove unnecessary imports \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "625105df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import Utilities\n",
    "import importlib\n",
    "importlib.reload(Utilities)\n",
    "\n",
    "import MLUtilities\n",
    "importlib.reload(MLUtilities)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler, PowerTransformer, RobustScaler\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, roc_auc_score, accuracy_score, balanced_accuracy_score, precision_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# from hyperopt.pyll import scope\n",
    "# from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "\n",
    "from hyperopt import hp,Trials,fmin,tpe,STATUS_OK\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1a17b",
   "metadata": {},
   "source": [
    "## Load and Setup Verification data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d9192",
   "metadata": {},
   "source": [
    "# Settings for Machine Learning Model \n",
    "\n",
    "Modified code to exclude all < 18 yo patients.\n",
    "\n",
    "Models based on first set of vital signs taken in ED. \n",
    "\n",
    "- DataSet 01: BP Systolic, Level of Consciousness, Pulse Rate (BPM), Respiration,  SpO2,  Temperature (Degrees C), O2 Flow\n",
    "    + 01_a : Require age 65+\n",
    "    + 01_b : 18 to 65 \n",
    "- DataSet 02: DataSet 1 excluding O2 Flow \n",
    "    + 02_a : Require age 65+\n",
    "    + 02_b : 18 to 65 \n",
    "- DataSet 11: DataSet 1 plus Gender \n",
    "    + 11_a : Require age 65+\n",
    "    + 11_b : 18 to 65 \n",
    "- DataSet 12: DataSet 2 plus Gender \n",
    "    + 12_a : Require age 65+\n",
    "    + 12_b : 18 to 65 \n",
    "- DataSet 21: DataSet 1 plus Gender and Age\n",
    "    + 21_a : Require age 65+\n",
    "    + 21_b : 18 to 65 \n",
    "- DataSet 22: DataSet 2 plus Gender and Age\n",
    "    + 22_a : Require age 65+\n",
    "    + 22_b : 18 to 65 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a72f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepsis SepsisFlag\n"
     ]
    }
   ],
   "source": [
    "# Sepsis HeartFailure PE Pneumonia COPD UTI\n",
    "# SepsisPneumonia\n",
    "Diagnosis =   \"Sepsis\"\n",
    "# Diagnosis = 'SepsisPneumonia'\n",
    "# Diagnosis = 'Admission'\n",
    "# Diagnosis = 'GenMed'\n",
    "\n",
    "DiagnosisString=Diagnosis+'Flag'\n",
    "\n",
    "\n",
    "# DataSet = 'DataSet3a'\n",
    "\n",
    "# MLModel = 'randomforest'\n",
    "\n",
    "print(Diagnosis,DiagnosisString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838cd520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_2023-01-01_2024-01-01_Training_Stage_01.pkl\n"
     ]
    }
   ],
   "source": [
    "start_date =  '2023-01-01'  #dates[Facility][0]\n",
    "end_date   =  '2024-01-01' #dates[Facility][1]\n",
    "\n",
    "select_start_date = '2023-01-01'\n",
    "\n",
    "DataReasons = \"Training\"\n",
    "\n",
    "Data_Storage_File = 'DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_{}_{}_{}_Stage_01.pkl'.format(start_date,end_date,DataReasons)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "\n",
    "with open(Data_Storage_File, 'rb') as file:\n",
    "    Emergency_IPInfo_Complete_Numeric = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08896659",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emergency_IPInfo_Complete_Numeric = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION>17].copy()\n",
    "\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(0,17),'age_range']='0-17'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(18,33),'age_range']='18-33'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(34,48),'age_range']='34-48'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(49,64),'age_range']='49-64'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(65,78),'age_range']='65-78'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(79,98),'age_range']='79-98'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(98,120),'age_range']='98+'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(121,200),'age_range']='Unknown'\n",
    "\n",
    "Emergency_IPInfo_Complete_Numeric['IndiginousFlag'] = 0  # np.where((Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isna()|Emergency_IPInfo_Complete_Numeric.IndiginousStatus=='Not Aboriginal-TSI'),0,1)\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isin(['Aboriginal','Aboriginal and TSI', 'TSI']),'IndiginousFlag'] = 1\n",
    "\n",
    "\n",
    "# DiagnosisString='SepsisFlag'\n",
    "\n",
    "if Diagnosis == \"SepsisPneumonia\":\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric.SepsisFlag==1)|(Emergency_IPInfo_Complete_Numeric.PneumoniaFlag==1), DiagnosisString] = 1\n",
    "\n",
    "if Diagnosis == 'Admission':\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>24), DiagnosisString] = 1\n",
    "    \n",
    "    if DataSet == 'DataSet5':\n",
    "        Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "        Emergency_IPInfo_Complete_Numeric.loc[ (Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>6), DiagnosisString] = 1\n",
    "\n",
    "\n",
    "if Diagnosis == 'GenMed':\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    for g in GenMedList:\n",
    "        Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric.GROUPCODE.str.contains(g))  & (Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>6), DiagnosisString] = 1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8165b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(MLUtilities)\n",
    "Emergency_IPInfo_Complete_Numeric = MLUtilities.setNumeric(Emergency_IPInfo_Complete_Numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a79afbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est=55\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler()),  # StandardScaler #MinMaxScaler # RobustScaler\n",
    "        # ('scaler', RobustScaler(quantile_range=((25.0,75.0)))),  # StandardScaler #MinMaxScaler # RobustScaler\n",
    "        #('skew', FunctionTransformer(log_transform))\n",
    "    ])\n",
    "\n",
    "space4xgbsepsis = {\n",
    "    'random_state': n_est, \n",
    "    'max_depth': hp.choice('max_depth', np.arange(1,30, 1, dtype=int)), \n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(1, 200, 1, dtype=int)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),  # New \n",
    "    'subsample':hp.uniform('subsample', 0.5, 1.),     # New\n",
    "     }\n",
    "\n",
    "space4rf = {\n",
    "    'random_state': n_est,\n",
    "    'class_weight': 'balanced',\n",
    "    'max_depth':  None, #    hp.choice('max_depth', np.arange(5, 30, 1, dtype=int)),\n",
    "    #'max_features':    #hp.choice('max_features', np.arange(2, 10, 1, dtype=int)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(100, 500, 10, dtype=int))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57b09d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning_rf_sepsis(trial_params):\n",
    "        \n",
    "    classifier = RandomForestClassifier(**trial_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", classifier)\n",
    "        ])\n",
    "    model.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "    predictions_valid = model.predict_proba(X_valid)\n",
    "    ypreds = np.delete(predictions_valid,[0],1)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold =   np.interp(0.85,tpr,thresholds)    #thresholds[idx]\n",
    "    false_positive =  np.interp(0.85,tpr,fpr)      # fpr[idx]\n",
    "    # redo predictions with new threshold \n",
    "    y_select_2 = np.where(ypreds<threshold,0,1)\n",
    "    auc_score = roc_auc_score(y_valid, ypreds, multi_class=\"ovr\", average=\"weighted\")\n",
    "    accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "    balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "    recall  =recall_score(y_valid, y_select_2)\n",
    "    precision = precision_score(y_valid, y_select_2)\n",
    "    f1 = f1_score(y_valid, y_select_2)\n",
    "    \n",
    "\n",
    "    \n",
    "    scores = {\"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score,\n",
    "              \"threshold\":threshold}\n",
    "\n",
    "    return {'status': STATUS_OK, 'loss': false_positive, 'model': model, 'attachments':scores}\n",
    "\n",
    "\n",
    "def hyperparameter_tuning_xgb_sepsis(trial_params):\n",
    "            \n",
    "    classifier = xgb.XGBClassifier(**trial_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", classifier)\n",
    "        ])\n",
    "    \n",
    "    model.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "    predictions_valid = model.predict_proba(X_valid)\n",
    "    ypreds = np.delete(predictions_valid,[0],1)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold =   np.interp(0.85,tpr,thresholds)    #thresholds[idx]\n",
    "    false_positive =  np.interp(0.85,tpr,fpr)      # fpr[idx]\n",
    "    # redo predictions with new threshold \n",
    "    y_select_2 = np.where(ypreds<threshold,0,1)\n",
    "    auc_score = roc_auc_score(y_valid, ypreds, multi_class=\"ovr\", average=\"weighted\")\n",
    "    accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "    balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "    recall  =recall_score(y_valid, y_select_2)\n",
    "    precision = precision_score(y_valid, y_select_2)\n",
    "    f1 = f1_score(y_valid, y_select_2)\n",
    "    \n",
    "\n",
    "\n",
    "    scores = {\"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score,\n",
    "              \"threshold\":threshold}\n",
    "\n",
    "    return {'status': STATUS_OK, 'loss': false_positive, 'model': model, 'attachments':scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32a4cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataSet01\n",
      "Diagnosis being investigated = SepsisFlag\n",
      "Total Number of Cases = 277021\n",
      "Number of SepsisFlag Cases  2733\n",
      "['FirstBPSystolic', 'FirstLevelofConsciousness', 'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2', 'FirstTemperatureDegreesC', 'SepsisFlag', 'FirstO2Flow']\n",
      "100%|██████████| 20/20 [00:23<00:00,  1.20s/trial, best loss: 0.24198840643114952]\n",
      "100%|██████████| 2/2 [00:53<00:00, 26.80s/trial, best loss: 0.446570534017649] \n",
      "Results/Nov_2024_SepsisFlag_DataSet01_BestFit_Models_Pathway_ED.pkl\n"
     ]
    }
   ],
   "source": [
    "for DataSet in ['DataSet01',#'DataSet01_a','DataSet01_b','DataSet02','DataSet02_a','DataSet02_b',\n",
    "                #'DataSet11',#'DataSet11_a','DataSet11_b','DataSet12','DataSet12_a','DataSet12_b',\n",
    "                #'DataSet21',#'DataSet21_a','DataSet21_b','DataSet22','DataSet22_a','DataSet22_b',]:\n",
    "]:\n",
    "    \n",
    "    n_trials = 2\n",
    "    \n",
    "    AnalysisVariable =['FirstBPSystolic', 'FirstLevelofConsciousness',\n",
    "       'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2',\n",
    "       'FirstTemperatureDegreesC', DiagnosisString]\n",
    "\n",
    "    if '1_' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if '01' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if '11' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if '21' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if ('DataSet1' in DataSet):\n",
    "        AnalysisVariable.append('GENDERCODE')\n",
    "    if ('DataSet2' in DataSet):\n",
    "        AnalysisVariable.append('GENDERCODE')\n",
    "        AnalysisVariable.append('AGEONADMISSION')\n",
    "\n",
    "        \n",
    "    if '_a' in DataSet:\n",
    "        print(\"check\")\n",
    "        df = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION>64].copy()\n",
    "    elif '_b' in DataSet:\n",
    "        df = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION<65].copy()\n",
    "    else: \n",
    "        df = Emergency_IPInfo_Complete_Numeric.copy()\n",
    "        \n",
    "        \n",
    "        \n",
    "    df.name='{} diagnosis detected from full Diagnosis list, updated'.format(Diagnosis)\n",
    "    importlib.reload(MLUtilities)\n",
    "    df = MLUtilities.setDefaults(df)\n",
    "\n",
    "    print(\"\\n{}\".format(DataSet))\n",
    "    print(\"Diagnosis being investigated = {}\".format(DiagnosisString))\n",
    "    print(\"Total Number of Cases = {}\".format(len(df.index)))\n",
    "    print(\"Number of {} Cases \".format(DiagnosisString),len(df[df[DiagnosisString]==1]))\n",
    "    print(AnalysisVariable)\n",
    "    \n",
    "    df_temp = df[AnalysisVariable].copy()\n",
    "    \n",
    "    if 'GENDERCODE' in AnalysisVariable:\n",
    "        df_temp['GENDERCODE'] = df_temp['GENDERCODE'].astype('category')\n",
    "    \n",
    "    # SMOTE does not work if NAN is allowed so int instead of Int \n",
    "\n",
    "    int_features = df_temp.select_dtypes(\n",
    "        include=[ 'int64', 'Int64', 'int32']).columns\n",
    "\n",
    "    for key in int_features:\n",
    "        df_temp[key] = df_temp[key].astype('int64')\n",
    "    \n",
    "    y = df_temp[[DiagnosisString]]\n",
    "    X = df_temp[AnalysisVariable].drop(DiagnosisString, axis=1).copy()\n",
    "    x_vars = X.columns\n",
    "    \n",
    "    skew_vars = []\n",
    "\n",
    "    \n",
    "    numeric_features = X.drop(skew_vars, axis=1).select_dtypes(\n",
    "        include=['float64', 'int64']).columns\n",
    "\n",
    "    categorical_features = X.select_dtypes(\n",
    "        include=['category', 'object']).columns\n",
    "    \n",
    "    category_values = []\n",
    "    for i in categorical_features:\n",
    "        tmp = pd.unique(df_temp[i]).tolist()\n",
    "        tmp.sort()\n",
    "        print(i,tmp)\n",
    "        category_values.append(tmp)\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore',categories=category_values   ))])  # OrdinalEncoder() #OneHotEncoder(drop='first')\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numeric', numeric_transformer, numeric_features),\n",
    "                ('categorical', categorical_transformer, categorical_features)\n",
    "            ])\n",
    "\n",
    "    def pip_f(reg):\n",
    "        pip = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', reg)\n",
    "        ])\n",
    "        return(pip)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    if len(categorical_features)>0:\n",
    "        smote = SMOTENC(random_state=42, categorical_features=[X_train.columns.get_loc(c) for c in categorical_features])\n",
    "        X_train, y_train= smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    # n_trials = 2\n",
    "    \n",
    "    trialsRandomForest = Trials()\n",
    "    trialsXGBoost = Trials()\n",
    "\n",
    "\n",
    "    best_params_XGB = fmin(fn = hyperparameter_tuning_xgb_sepsis,\n",
    "                        space = space4xgbsepsis,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = n_trials*10, \n",
    "                        trials = trialsXGBoost\n",
    "                        )\n",
    "\n",
    "    best_params_RandomForest = fmin(fn=hyperparameter_tuning_rf_sepsis,\n",
    "                        space=space4rf,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=n_trials,\n",
    "                        trials=trialsRandomForest\n",
    "                        )\n",
    "    \n",
    "    scoreRandomForest =  [t['result']['loss'] for t in trialsRandomForest.trials]\n",
    "    best_model_RandomForest=trialsRandomForest.results[np.argmin([r['loss'] for r in trialsRandomForest.results])]['model']\n",
    "\n",
    "\n",
    "    scoreXGBoost = [t['result']['loss'] for t in trialsXGBoost.trials]\n",
    "    best_model_XGBoost=trialsXGBoost.results[np.argmin([r['loss'] for r in trialsXGBoost.results])]['model']\n",
    "    \n",
    "    all_cols = np.concatenate([numeric_features])\n",
    "\n",
    "    if len(categorical_features)>0:\n",
    "        new_cat_cols =best_model_RandomForest['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(categorical_features)\n",
    "        all_cols = np.concatenate([numeric_features,new_cat_cols])\n",
    "\n",
    "\n",
    "    xgbValues = []\n",
    "    varStrings = [\"falsePositive\",  \"threshold\",\"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\"]\n",
    "    scores = {}\n",
    "    i=0\n",
    "    for i in range(n_trials*10):\n",
    "        scores = {}\n",
    "        # if i < 2:\n",
    "        scores['max_depth'] = trialsXGBoost.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "        scores['n_estimators'] = trialsXGBoost.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "        scores['learning_rate'] = trialsXGBoost.trials[i]['misc']['vals']['learning_rate'][0]+1\n",
    "        scores['subsample'] = trialsXGBoost.trials[i]['misc']['vals']['subsample'][0]+1\n",
    "        # scores['seed'] = trialsXGBoost.trials[i]['misc']['vals']['seed'][0]\n",
    "            # \n",
    "            # 'n_estimators'\n",
    "        for c in varStrings:\n",
    "            # print(c)\n",
    "            key = \"ATTACH::{}::{}\".format(i,c)\n",
    "            scores[c] = trialsXGBoost.attachments[key]\n",
    "            scores[\"i\"] = i\n",
    "        xgbValues.append(scores)\n",
    "    # print (scores)\n",
    "    trials_XGB_df = pd.DataFrame.from_dict(xgbValues)\n",
    "\n",
    "    rfValues = []\n",
    "    varStrings = [\"falsePositive\", \"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\",]\n",
    "    scores = {}\n",
    "    i=0\n",
    "    for i in range(n_trials):\n",
    "        scores = {}\n",
    "        # if i < 2:\n",
    "        # scores['max_depth'] = trialsRandomForest.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "        scores['n_estimators'] = trialsRandomForest.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "\n",
    "            # \n",
    "            # 'n_estimators'\n",
    "        for c in varStrings:\n",
    "            # print(c)\n",
    "            key = \"ATTACH::{}::{}\".format(i,c)\n",
    "            scores[c] = trialsRandomForest.attachments[key]\n",
    "            scores[\"i\"] = i\n",
    "        rfValues.append(scores)\n",
    "\n",
    "    trials_rf_df = pd.DataFrame.from_dict(rfValues)\n",
    "    \n",
    "    ObjectsToSaveRF = [best_model_RandomForest, best_model_XGBoost, all_cols, X_valid, y_valid,trials_rf_df,trials_XGB_df]\n",
    "\n",
    "    # timestr =  str(datetime.datetime.now().strftime('%Y_%m_%d'))\n",
    "    # Data_Storage_File = 'Results/GenMed_SepsisPathway_{}_{}_FeatureImportances.pkl'.format(DataSet,DiagnosisString)\n",
    "\n",
    "    Data_Storage_File = 'Results/Nov_2024_{}_{}_BestFit_Models_Pathway_ED.pkl'.format(DiagnosisString,DataSet)\n",
    "    print(Data_Storage_File)\n",
    "\n",
    "    with open(Data_Storage_File, 'wb') as file:  \n",
    "        pickle.dump(ObjectsToSaveRF, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25fcb813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trialsXGBoost.results[0]['model'][1].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b7c8612",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = np.concatenate([numeric_features])\n",
    "\n",
    "if len(categorical_features)>0:\n",
    "    new_cat_cols =best_model_RandomForest['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(categorical_features)\n",
    "    all_cols = np.concatenate([numeric_features,new_cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "943d9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbValues = []\n",
    "varStrings = [\"falsePositive\",  \"threshold\",\"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\"]\n",
    "scores = {}\n",
    "i=0\n",
    "for i in range(n_trials*10):\n",
    "    scores = {}\n",
    "    # if i < 2:\n",
    "    scores['max_depth'] = trialsXGBoost.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "    scores['n_estimators'] = trialsXGBoost.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "    scores['learning_rate'] = trialsXGBoost.trials[i]['misc']['vals']['learning_rate'][0]+1\n",
    "    scores['subsample'] = trialsXGBoost.trials[i]['misc']['vals']['subsample'][0]+1\n",
    "    # scores['seed'] = trialsXGBoost.trials[i]['misc']['vals']['seed'][0]\n",
    "        # \n",
    "        # 'n_estimators'\n",
    "    for c in varStrings:\n",
    "        # print(c)\n",
    "        key = \"ATTACH::{}::{}\".format(i,c)\n",
    "        scores[c] = trialsXGBoost.attachments[key]\n",
    "        scores[\"i\"] = i\n",
    "    xgbValues.append(scores)\n",
    "# print (scores)\n",
    "trials_XGB_df = pd.DataFrame.from_dict(xgbValues)\n",
    "\n",
    "rfValues = []\n",
    "varStrings = [\"falsePositive\", \"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\",]\n",
    "scores = {}\n",
    "i=0\n",
    "for i in range(n_trials):\n",
    "    scores = {}\n",
    "    # if i < 2:\n",
    "    # scores['max_depth'] = trialsRandomForest.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "    scores['n_estimators'] = trialsRandomForest.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "\n",
    "        # \n",
    "        # 'n_estimators'\n",
    "    for c in varStrings:\n",
    "        # print(c)\n",
    "        key = \"ATTACH::{}::{}\".format(i,c)\n",
    "        scores[c] = trialsRandomForest.attachments[key]\n",
    "        scores[\"i\"] = i\n",
    "    rfValues.append(scores)\n",
    "\n",
    "trials_rf_df = pd.DataFrame.from_dict(rfValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjectsToSaveRF = [best_model_RandomForest, best_model_XGBoost, all_cols, X_valid, y_valid,trials_rf_df,trials_XGB_df]\n",
    "\n",
    "# timestr =  str(datetime.datetime.now().strftime('%Y_%m_%d'))\n",
    "# Data_Storage_File = 'Results/GenMed_SepsisPathway_{}_{}_FeatureImportances.pkl'.format(DataSet,DiagnosisString)\n",
    "\n",
    "Data_Storage_File = 'Results/Nov_2024_{}_{}_BestFit_Models_Pathway_ED.pkl'.format(DiagnosisString,DataSet)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "with open(Data_Storage_File, 'wb') as file:  \n",
    "    pickle.dump(ObjectsToSaveRF, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceihml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
