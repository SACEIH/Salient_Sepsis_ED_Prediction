{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Sepsis Pathway \n",
    "\n",
    "Setup Libraries and plotting defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "c:\\Users\\ibertr02\\venvs\\ceihml\\Lib\\site-packages\\snowflake\\connector\\options.py:103: UserWarning: You have an incompatible version of 'pyarrow' installed (15.0.2), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n",
      "Failed to import ArrowResult. No Apache Arrow result set format can be used. ImportError: DLL load failed while importing arrow_iterator: The specified procedure could not be found.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import statsmodels.formula.api as smf\n",
    "#from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from pandasql import sqldf\n",
    "import sqlalchemy\n",
    "import pyodbc\n",
    "\n",
    "import dfply as dfp\n",
    "from dfply import *\n",
    "\n",
    "import datetime\n",
    "from datetime import *\n",
    "\n",
    "import pyodbc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics         import balanced_accuracy_score, precision_score, classification_report\n",
    "from sklearn.metrics         import recall_score, f1_score, make_scorer, cohen_kappa_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import forestci as fci\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler, PowerTransformer, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer, PowerTransformer\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, roc_auc_score, accuracy_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#from statsmodels.tools.tools import add_constant\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "n_est=55\n",
    "\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import Utilities\n",
    "import importlib\n",
    "importlib.reload(Utilities)\n",
    "\n",
    "import MLUtilities\n",
    "importlib.reload(MLUtilities)\n",
    "\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "plt.style.use('./CEIH.mplstyle')\n",
    "color_dict = {0: to_rgba('#32C0D2', 1),\n",
    "                1: to_rgba(\"#E0B165\", 1),}\n",
    "\n",
    "cmap_blended = sns.blend_palette([\"#ADE6ED\",\"#70D3E0\",\"#32C0D2\",\"#289AA8\",\"#307078\"], as_cmap=True)\n",
    "\n",
    "\n",
    "import math\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "    \n",
    "OtherValues = {'TriageCategory_2':'Triage Category 2', 'SoBFlag': 'Shortness of Breath', 'TriageCategory_4':'Triage Category 4',\n",
    "               'TriageCategory_1':'Triage Category 1', 'TriageCategory_5':'Triage Category 5', 'TriageCategory_3':'Triage Category 3',\n",
    "             'FirstGCSScoreAdult':'Glasgow Coma Scale',\n",
    "               'FirstUrinalysisBlood': 'Urinalysis Blood', 'IndigenousStatusDescription_Not Aboriginal-TSI':  'Non Indiginous',\n",
    "               'IndigenousStatusDescription_Not Stated':  'Indiginous Status not stated', 'FirstUrinalysisLeukocytes':'Urinalysis Leukocytes',\n",
    "               'FirstPulseRateBPM':'Pulse Rate', 'FirstRespiration':'Respiration Rate', 'FirstSpO2':'O2 Saturation (%)',  'Gender_Male':'Sex - Male',\n",
    "               'FirstLevelofConsciousness':'Level of Consciousness', 'IndigenousStatusDescription_Aboriginal and TSI':'Aboriginal and TSI',\n",
    "               'IndigenousStatusDescription_TSI':'TSI','Gender_Indeterminate':'Sex - Indeterminate', 'Gender_Unknown':'Sex - Unknown',\n",
    "               'FirstO2Flow':'O2 Flow '\n",
    "               }\n",
    "\n",
    "\n",
    "plotSettings = {\n",
    "        #  ( bins, xmin, xmax, log/linear)\n",
    "        'AGEONADMISSION':(50,20,110,'linear','Age (y)', False, 0,0),\n",
    "        \n",
    "        \n",
    "        'FirstBloodGlucose':(50,0,100,'log','Blood Glucose [mmol/L]', False,0, 0),\n",
    "        'FirstTemperatureDegreesC':(50,30,45,'log', r\"Temperature [$^\\circ$C]\", True,35.5,38.1),\n",
    "                'FirstWeightKg':(50,50,150,'log','Weight [kg]', False, 0,0),\n",
    "\n",
    "        \n",
    "        'FirstPainAssessment': (11,-0.5,10.5,'log','Pain Assessment', False, 0,0),\n",
    "        'FirstBPSystolic': (50,50,250,'log', 'BP Systolic [mm Hg]',True, 100,170 ),\n",
    "        'FirstBPDiastolic': (50,0,200,'log', 'BP Diastolic [mm Hg]', False,0,0),\n",
    "        'FirstEstimatedGlomerularFiltrationRate': (50,0,100,'log',r\"Estimated Glomerular Filtration Rate [mL/min/1.73m$^{2}$]\", True, 60, 100),\n",
    "        'FirstCreatinine': (50,0,800,'log',r\"Creatinine - Serum [$\\mu$mol/L]\", True, 45, 110),\n",
    "        'FirstAlbumin': (60,0,60,'log','Albumin  Level [g/L]', True, 30, 48),\n",
    "        'FirstTotalBilirubin': (60,0,100,'log',r\"Total Bilirubin Level [$\\mu$mol/L]\", True, 2, 24 ),\n",
    "        'FirstAlkalinePhosphatase': (60,0,800,'log','Alkaline Phosphatase Level [U/L]',True, 30,110),\n",
    "        'FirstAlanineAminotransferase': (60,0,700,'log','Alanine Aminotransferase Level [U/L]', True,0,55),\n",
    "        'FirstAspartateAminotransferase': (60,0,700,'log','Aspartate Aminotransferase Level [U/L]', True, 0,45),\n",
    "        'FirstGammaGlutamylTransferase': (60,0,700,'log','Gamma Glutamyl Transferase Level [U/L]', True, 0, 60),\n",
    "        'FirstLactateDehydrogenase': (60,0,1200,'log','Lactate Dehydrogenase [U/L]', True, 120, 250),\n",
    "        'FirstHaemoglobin': (50,10, 220,'log','Haemoglobin [g/L]', True, 115, 175),\n",
    "        'FirstWhiteCellCount': (50,0, 50,'log',r\"White Cell Count [$\\times 10^{9}$/L]\",True, 4,11),\n",
    "        'FirstPlateletCount': (50,0, 1000,'log',r\"Platelet Count [$\\times 10^{9}$/L]\",True,150,500),\n",
    "        'FirstNeutrophils': (50,0, 50,'log',r\"Absolute Neutrophil Count [$\\times 10^{9}$/L]\",True,1.80,7.50),\n",
    "        'FirstDDimer': (40,0, 20,'log',r\"D-Dimer [mg/L]\",True,0,0.79),\n",
    "        'FirstCreactiveprotein': (50,0, 600,'log',r\"C-Reactive Protein [mg/L]\",True, 0,8),\n",
    "        'FirstTroponinT': (50,0, 600,'log',r\"Troponin T Level [mg/L]\",True,0,16),\n",
    "        'FirstNTproBNP': (50,0, 40000,'log',r\"NT-pro Brain Natriuretic Peptide [mg/L]\",True,0,124),\n",
    "        \n",
    "        'FirstAnionGapVenous': (50,0, 50,'log',r\"Anion Gap Venous [mmol/L]\", True, 7, 17),\n",
    "        'FirstAnionGapArterial': (50,0, 50,'log',r\"Anion Gap Arterial [mmol/L]\",  True, 7, 17),\n",
    "        'FirstBaseExcessVenous': (50,-30, 30,'log',r\"Base Excess Venous [mmol/L]\", True, -3, 3),\n",
    "        'FirstBaseExcessArterial': (50,-30, 30,'log',r\"Base Excess Arterial [mmol/L]\", True, -3, 3),\n",
    "        'FirstBilirubinVenous': (60,0, 60,'log',r\"Bilirubin Venous [$\\mu$mol/L]\", True, 2,24),\n",
    "        'FirstBilirubinArterial': (60,0, 60,'log',r\"Bilirubin Arterial [$\\mu$mol/L]\", True, 2,24),\n",
    "        'FirstCarboxyhaemoglobinVenous': (50,0, 20,'log',r\"Carboxyhaemoglobin Venous [%]\", True, 0.3, 1.8),\n",
    "        'FirstCarboxyhaemoglobinArterial': (50,0, 20,'log',r\"Carboxyhaemoglobin Arterial [%]\", True, 0.3, 1.8),\n",
    "        'FirstChlorideDirectVenous': (50,50, 150,'log',r\"Chloride Direct Venous [mmol/L]\",False, 100,109),\n",
    "        'FirstChlorideDirectArterial': (50,50, 150,'log',r\"Chloride Direct Arterial [mmol/L]\", True, 100,109),\n",
    "        'FirstCreatinineVenous':(50,0,500,'log',r\"Creatinine Venous [$\\mu$mol/L]\", True, 50, 120),\n",
    "        'FirstCreatinineArterial':(50,0,500,'log',r\"Creatinine Arterial [$\\mu$mol/L]\", True, 50,120),\n",
    "        'FirstGlucoseVenous':(50,0,30,'log',r\"Glucose  Venous [mmol/L]\", False,0,0),\n",
    "        'FirstGlucoseArterial':(50,0,30,'log',r\"Glucose  Arterial [mmol/L]\", True,2.6,5.6),\n",
    "        'FirstIonised Calcium Venous':(50,0,2,'log',r\"Ionised Calcium Venous [mmol/L]\", True, 1.1, 1.3),\n",
    "        'FirstIonised Calcium Arterial':(50,0,2,'log',r\"Ionised Calcium Arterial [mmol/L]\", True, 1.1, 1.3),\n",
    "        'FirstLactateVenous':(50,0,30,'log',r\"Lactate Venous [mmol/L]\", True, 0.2, 2.0),\n",
    "        'FirstLactateArterial':(50,0,30,'log',r\"Lactate Arterial [mmol/L]\", True, 0.2, 2.0),\n",
    "        'FirstMethaemoglobinVenous': (20,0, 3,'log',r\"Methaemoglobin Venous [%]\", True, 0.4, 1.2),\n",
    "        'FirstMethaemoglobinArterial': (20,0, 3,'log',r\"Methaemoglobin Arterial [%]\", True, 0.2,0.6),\n",
    "        'FirstOxygenSaturationVenous': (50,0, 100,'log',r\"Oxygen Saturation Venous [%]\", False, 0,0),\n",
    "        'FirstOxygenSaturationArterial': (50,0, 100,'log',r\"Oxygen Saturation Arterial [%]\", True,95, 99),\n",
    "        'FirstOxyhaemoglobinVenous': (50,0, 100,'log',r\"Oxyhaemoglobin Venous [%]\", False, 0,0),\n",
    "        'FirstOxyhaemoglobinArterial': (50,0, 100,'log',r\"Oxyhaemoglobin Arterial [%]\", False, 0,0),\n",
    "        'FirstReducedHaemoglobinVenous': (50,0, 100,'log',r\"Reduced Haemoglobin Venous [%]\", False, 0,0),\n",
    "        'FirstReducedHaemoglobinArterial': (50,0, 100,'log',r\"Reduced Haemoglobin Arterial [%]\", False, 0,0),\n",
    "        'FirstTotalHaemoglobinVenous': (50,10, 220,'log','Total Haemoglobin Venous [g/L]', True, 115,180),\n",
    "        'FirstTotalHaemoglobinArterial': (50,10, 220,'log','Total Haemoglobin Arterial [g/L]', True, 115,180), \n",
    "        'FirstpCO2Venous': (50,0,150,'log', 'pCO2 Venous [mm Hg]', True,41,51),\n",
    "        'FirstpCO2Arterial': (50,0,150,'log', 'pCO2 Arterial [mm Hg]', True, 35, 45 ),\n",
    "        'FirstpO2Venous': (50,0,200,'log', 'pO2 Venous [mm Hg]', True, 25,40),\n",
    "        'FirstpO2Arterial': (50,0,200,'log', 'pO2 Arterial [mm Hg]', True,67, 108),\n",
    "        'FirstpHVenous': (50,6.8,7.8,'log', 'pH Venous', True, 7.32,7.42),\n",
    "        'FirstpHArterial': (50,6.8,7.8,'log', 'pH Arterial', True, 7.36, 7.44),\n",
    "        'FirstPotassiumDirectVenous':(50,0,10,'log',r\"Potassium Direct Venous [mmol/L]\", False, 0,0),\n",
    "        'FirstPotassiumDirectArterial':(50,0,10,'log',r\"Potassium Direct Arterial [mmol/L]\", True, 3.1, 4.2),\n",
    "        'FirstSodiumDirectVenous':(50,100,180,'log',r\"Sodium Direct Venous [mmol/L]\", False, 0,0),\n",
    "        'FirstSodiumDirectArterial':(50,100,180,'log',r\"Sodium Direct Arterial [mmol/L]\", True, 137, 145),}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenMedList = ['LMH-LGMED','LMH-LAMU',\n",
    "              \"MPH-MGMED\", \n",
    "              \"FMC-GENMED\",\n",
    "              \"NHS-GENMED\",\n",
    "              \"RAH-GENMED\",\n",
    "              \"QEH-GENMED\", 'QEH-GM-AMU'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Machine Learning Model \n",
    "\n",
    "Modified code to exclude all < 18 yo patients.\n",
    "\n",
    "Models based on first set of vital signs taken in ED. \n",
    "\n",
    "- DataSet 01: BP Systolic, Level of Consciousness, Pulse Rate (BPM), Respiration,  SpO2,  Temperature (Degrees C), O2 Flow\n",
    "    + 01_a : Require age 65+\n",
    "    + 01_b : 18 to 65 \n",
    "- DataSet 02: DataSet 1 excluding O2 Flow \n",
    "    + 02_a : Require age 65+\n",
    "    + 02_b : 18 to 65 \n",
    "- DataSet 11: DataSet 1 plus Gender \n",
    "    + 11_a : Require age 65+\n",
    "    + 11_b : 18 to 65 \n",
    "- DataSet 12: DataSet 2 plus Gender \n",
    "    + 12_a : Require age 65+\n",
    "    + 12_b : 18 to 65 \n",
    "- DataSet 21: DataSet 1 plus Gender and Age\n",
    "    + 21_a : Require age 65+\n",
    "    + 21_b : 18 to 65 \n",
    "- DataSet 22: DataSet 2 plus Gender and Age\n",
    "    + 22_a : Require age 65+\n",
    "    + 22_b : 18 to 65 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepsis SepsisFlag\n"
     ]
    }
   ],
   "source": [
    "# Sepsis HeartFailure PE Pneumonia COPD UTI\n",
    "# SepsisPneumonia\n",
    "Diagnosis =   \"Sepsis\"\n",
    "# Diagnosis = 'SepsisPneumonia'\n",
    "# Diagnosis = 'Admission'\n",
    "# Diagnosis = 'GenMed'\n",
    "\n",
    "DiagnosisString=Diagnosis+'Flag'\n",
    "\n",
    "\n",
    "# DataSet = 'DataSet3a'\n",
    "\n",
    "# MLModel = 'randomforest'\n",
    "\n",
    "print(Diagnosis,DiagnosisString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_2023-01-01_2024-01-01_Training_Stage_01.pkl\n"
     ]
    }
   ],
   "source": [
    "start_date =  '2023-01-01'  #dates[Facility][0]\n",
    "end_date   =  '2024-01-01' #dates[Facility][1]\n",
    "\n",
    "select_start_date = '2023-01-01'\n",
    "\n",
    "DataReasons = \"Training\"\n",
    "\n",
    "Data_Storage_File = 'DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_{}_{}_{}_Stage_01.pkl'.format(start_date,end_date,DataReasons)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "\n",
    "with open(Data_Storage_File, 'rb') as file:\n",
    "    Emergency_IPInfo_Complete_Numeric = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emergency_IPInfo_Complete_Numeric = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION>17].copy()\n",
    "\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(0,17),'age_range']='0-17'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(18,33),'age_range']='18-33'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(34,48),'age_range']='34-48'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(49,64),'age_range']='49-64'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(65,78),'age_range']='65-78'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(79,98),'age_range']='79-98'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(98,120),'age_range']='98+'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(121,200),'age_range']='Unknown'\n",
    "\n",
    "Emergency_IPInfo_Complete_Numeric['IndiginousFlag'] = 0  # np.where((Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isna()|Emergency_IPInfo_Complete_Numeric.IndiginousStatus=='Not Aboriginal-TSI'),0,1)\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isin(['Aboriginal','Aboriginal and TSI', 'TSI']),'IndiginousFlag'] = 1\n",
    "\n",
    "\n",
    "# DiagnosisString='SepsisFlag'\n",
    "\n",
    "if Diagnosis == \"SepsisPneumonia\":\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric.SepsisFlag==1)|(Emergency_IPInfo_Complete_Numeric.PneumoniaFlag==1), DiagnosisString] = 1\n",
    "\n",
    "if Diagnosis == 'Admission':\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>24), DiagnosisString] = 1\n",
    "    \n",
    "    if DataSet == 'DataSet5':\n",
    "        Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "        Emergency_IPInfo_Complete_Numeric.loc[ (Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>6), DiagnosisString] = 1\n",
    "\n",
    "\n",
    "if Diagnosis == 'GenMed':\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    for g in GenMedList:\n",
    "        Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric.GROUPCODE.str.contains(g))  & (Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>6), DiagnosisString] = 1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(MLUtilities)\n",
    "Emergency_IPInfo_Complete_Numeric = MLUtilities.setNumeric(Emergency_IPInfo_Complete_Numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler()),  # StandardScaler #MinMaxScaler # RobustScaler\n",
    "        # ('scaler', RobustScaler(quantile_range=((25.0,75.0)))),  # StandardScaler #MinMaxScaler # RobustScaler\n",
    "        #('skew', FunctionTransformer(log_transform))\n",
    "    ])\n",
    "\n",
    "space4xgbsepsis = {\n",
    "    'random_state': n_est, \n",
    "    'max_depth': hp.choice('max_depth', np.arange(1,30, 1, dtype=int)), \n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(1, 200, 1, dtype=int)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),  # New \n",
    "    'subsample':hp.uniform('subsample', 0.5, 1.),     # New\n",
    "     }\n",
    "\n",
    "space4rf = {\n",
    "    'random_state': n_est,\n",
    "    'class_weight': 'balanced',\n",
    "    'max_depth':  None, #    hp.choice('max_depth', np.arange(5, 30, 1, dtype=int)),\n",
    "    #'max_features':    #hp.choice('max_features', np.arange(2, 10, 1, dtype=int)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(100, 500, 10, dtype=int))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning_rf_sepsis(trial_params):\n",
    "        \n",
    "    classifier = RandomForestClassifier(**trial_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", classifier)\n",
    "        ])\n",
    "    model.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "    predictions_valid = model.predict_proba(X_valid)\n",
    "    ypreds = np.delete(predictions_valid,[0],1)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold =   np.interp(0.85,tpr,thresholds)    #thresholds[idx]\n",
    "    false_positive =  np.interp(0.85,tpr,fpr)      # fpr[idx]\n",
    "    # redo predictions with new threshold \n",
    "    y_select_2 = np.where(ypreds<threshold,0,1)\n",
    "    auc_score = roc_auc_score(y_valid, ypreds, multi_class=\"ovr\", average=\"weighted\")\n",
    "    accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "    balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "    recall  =recall_score(y_valid, y_select_2)\n",
    "    precision = precision_score(y_valid, y_select_2)\n",
    "    f1 = f1_score(y_valid, y_select_2)\n",
    "    \n",
    "\n",
    "    \n",
    "    scores = {\"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score,\n",
    "              \"threshold\":threshold}\n",
    "\n",
    "    return {'status': STATUS_OK, 'loss': false_positive, 'model': model, 'attachments':scores}\n",
    "\n",
    "\n",
    "def hyperparameter_tuning_xgb_sepsis(trial_params):\n",
    "            \n",
    "    classifier = xgb.XGBClassifier(**trial_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", classifier)\n",
    "        ])\n",
    "    \n",
    "    model.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "    predictions_valid = model.predict_proba(X_valid)\n",
    "    ypreds = np.delete(predictions_valid,[0],1)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold =   np.interp(0.85,tpr,thresholds)    #thresholds[idx]\n",
    "    false_positive =  np.interp(0.85,tpr,fpr)      # fpr[idx]\n",
    "    # redo predictions with new threshold \n",
    "    y_select_2 = np.where(ypreds<threshold,0,1)\n",
    "    auc_score = roc_auc_score(y_valid, ypreds, multi_class=\"ovr\", average=\"weighted\")\n",
    "    accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "    balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "    recall  =recall_score(y_valid, y_select_2)\n",
    "    precision = precision_score(y_valid, y_select_2)\n",
    "    f1 = f1_score(y_valid, y_select_2)\n",
    "    \n",
    "\n",
    "\n",
    "    scores = {\"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score,\n",
    "              \"threshold\":threshold}\n",
    "\n",
    "    return {'status': STATUS_OK, 'loss': false_positive, 'model': model, 'attachments':scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataSet01\n",
      "Diagnosis being investigated = SepsisFlag\n",
      "Total Number of Cases = 277021\n",
      "Number of SepsisFlag Cases  2733\n",
      "['FirstBPSystolic', 'FirstLevelofConsciousness', 'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2', 'FirstTemperatureDegreesC', 'SepsisFlag', 'FirstO2Flow']\n",
      "100%|██████████| 1000/1000 [34:38<00:00,  2.08s/trial, best loss: 0.23044952422618398]\n",
      "100%|██████████| 100/100 [2:06:33<00:00, 75.94s/trial, best loss: 0.3845679872609517]  \n",
      "Results/Nov_2024_SepsisFlag_DataSet01_BestFit_Models_Pathway_ED.pkl\n",
      "\n",
      "DataSet11\n",
      "Diagnosis being investigated = SepsisFlag\n",
      "Total Number of Cases = 277021\n",
      "Number of SepsisFlag Cases  2733\n",
      "['FirstBPSystolic', 'FirstLevelofConsciousness', 'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2', 'FirstTemperatureDegreesC', 'SepsisFlag', 'FirstO2Flow', 'GENDERCODE']\n",
      "GENDERCODE ['Female', 'Indeterminate', 'Male', 'Unknown']\n",
      "100%|██████████| 1000/1000 [1:20:36<00:00,  4.84s/trial, best loss: 0.2648100550512231]\n",
      "100%|██████████| 100/100 [8:37:33<00:00, 310.53s/trial, best loss: 0.3638149403915563] \n",
      "Results/Nov_2024_SepsisFlag_DataSet11_BestFit_Models_Pathway_ED.pkl\n",
      "\n",
      "DataSet21\n",
      "Diagnosis being investigated = SepsisFlag\n",
      "Total Number of Cases = 277021\n",
      "Number of SepsisFlag Cases  2733\n",
      "['FirstBPSystolic', 'FirstLevelofConsciousness', 'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2', 'FirstTemperatureDegreesC', 'SepsisFlag', 'FirstO2Flow', 'GENDERCODE', 'AGEONADMISSION']\n",
      "GENDERCODE ['Female', 'Indeterminate', 'Male', 'Unknown']\n",
      "100%|██████████| 1000/1000 [1:13:21<00:00,  4.40s/trial, best loss: 0.20398118779394073]\n",
      "100%|██████████| 100/100 [8:39:47<00:00, 311.87s/trial, best loss: 0.27172153560100615] \n",
      "Results/Nov_2024_SepsisFlag_DataSet21_BestFit_Models_Pathway_ED.pkl\n"
     ]
    }
   ],
   "source": [
    "for DataSet in ['DataSet01',#'DataSet01_a','DataSet01_b','DataSet02','DataSet02_a','DataSet02_b',\n",
    "                'DataSet11',#'DataSet11_a','DataSet11_b','DataSet12','DataSet12_a','DataSet12_b',\n",
    "                'DataSet21',#'DataSet21_a','DataSet21_b','DataSet22','DataSet22_a','DataSet22_b',]:\n",
    "]:\n",
    "    \n",
    "    n_trials = 100\n",
    "    \n",
    "    AnalysisVariable =['FirstBPSystolic', 'FirstLevelofConsciousness',\n",
    "       'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2',\n",
    "       'FirstTemperatureDegreesC', DiagnosisString]\n",
    "\n",
    "    if '1_' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if '01' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if '11' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if '21' in DataSet:\n",
    "        AnalysisVariable.append('FirstO2Flow')\n",
    "    if ('DataSet1' in DataSet):\n",
    "        AnalysisVariable.append('GENDERCODE')\n",
    "    if ('DataSet2' in DataSet):\n",
    "        AnalysisVariable.append('GENDERCODE')\n",
    "        AnalysisVariable.append('AGEONADMISSION')\n",
    "\n",
    "        \n",
    "    if '_a' in DataSet:\n",
    "        print(\"check\")\n",
    "        df = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION>64].copy()\n",
    "    elif '_b' in DataSet:\n",
    "        df = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION<65].copy()\n",
    "    else: \n",
    "        df = Emergency_IPInfo_Complete_Numeric.copy()\n",
    "        \n",
    "        \n",
    "        \n",
    "    df.name='{} diagnosis detected from full Diagnosis list, updated'.format(Diagnosis)\n",
    "    importlib.reload(MLUtilities)\n",
    "    df = MLUtilities.setDefaults(df)\n",
    "\n",
    "    print(\"\\n{}\".format(DataSet))\n",
    "    print(\"Diagnosis being investigated = {}\".format(DiagnosisString))\n",
    "    print(\"Total Number of Cases = {}\".format(len(df.index)))\n",
    "    print(\"Number of {} Cases \".format(DiagnosisString),len(df[df[DiagnosisString]==1]))\n",
    "    print(AnalysisVariable)\n",
    "    \n",
    "    df_temp = df[AnalysisVariable].copy()\n",
    "    \n",
    "    if 'GENDERCODE' in AnalysisVariable:\n",
    "        df_temp['GENDERCODE'] = df_temp['GENDERCODE'].astype('category')\n",
    "    \n",
    "    # SMOTE does not work if NAN is allowed so int instead of Int \n",
    "\n",
    "    int_features = df_temp.select_dtypes(\n",
    "        include=[ 'int64', 'Int64', 'int32']).columns\n",
    "\n",
    "    for key in int_features:\n",
    "        df_temp[key] = df_temp[key].astype('int64')\n",
    "    \n",
    "    y = df_temp[[DiagnosisString]]\n",
    "    X = df_temp[AnalysisVariable].drop(DiagnosisString, axis=1).copy()\n",
    "    x_vars = X.columns\n",
    "    \n",
    "    skew_vars = []\n",
    "\n",
    "    \n",
    "    numeric_features = X.drop(skew_vars, axis=1).select_dtypes(\n",
    "        include=['float64', 'int64']).columns\n",
    "\n",
    "    categorical_features = X.select_dtypes(\n",
    "        include=['category', 'object']).columns\n",
    "    \n",
    "    category_values = []\n",
    "    for i in categorical_features:\n",
    "        tmp = pd.unique(df_temp[i]).tolist()\n",
    "        tmp.sort()\n",
    "        print(i,tmp)\n",
    "        category_values.append(tmp)\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore',categories=category_values   ))])  # OrdinalEncoder() #OneHotEncoder(drop='first')\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numeric', numeric_transformer, numeric_features),\n",
    "                ('categorical', categorical_transformer, categorical_features)\n",
    "            ])\n",
    "\n",
    "    def pip_f(reg):\n",
    "        pip = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', reg)\n",
    "        ])\n",
    "        return(pip)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    if len(categorical_features)>0:\n",
    "        smote = SMOTENC(random_state=42, categorical_features=[X_train.columns.get_loc(c) for c in categorical_features])\n",
    "        X_train, y_train= smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    # n_trials = 2\n",
    "    \n",
    "    trialsRandomForest = Trials()\n",
    "    trialsXGBoost = Trials()\n",
    "\n",
    "\n",
    "    best_params_XGB = fmin(fn = hyperparameter_tuning_xgb_sepsis,\n",
    "                        space = space4xgbsepsis,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = n_trials*10, \n",
    "                        trials = trialsXGBoost\n",
    "                        )\n",
    "\n",
    "    best_params_RandomForest = fmin(fn=hyperparameter_tuning_rf_sepsis,\n",
    "                        space=space4rf,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=n_trials,\n",
    "                        trials=trialsRandomForest\n",
    "                        )\n",
    "    \n",
    "    scoreRandomForest =  [t['result']['loss'] for t in trialsRandomForest.trials]\n",
    "    best_model_RandomForest=trialsRandomForest.results[np.argmin([r['loss'] for r in trialsRandomForest.results])]['model']\n",
    "\n",
    "\n",
    "    scoreXGBoost = [t['result']['loss'] for t in trialsXGBoost.trials]\n",
    "    best_model_XGBoost=trialsXGBoost.results[np.argmin([r['loss'] for r in trialsXGBoost.results])]['model']\n",
    "    \n",
    "    all_cols = np.concatenate([numeric_features])\n",
    "\n",
    "    if len(categorical_features)>0:\n",
    "        new_cat_cols =best_model_RandomForest['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(categorical_features)\n",
    "        all_cols = np.concatenate([numeric_features,new_cat_cols])\n",
    "\n",
    "\n",
    "    xgbValues = []\n",
    "    varStrings = [\"falsePositive\",  \"threshold\",\"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\"]\n",
    "    scores = {}\n",
    "    i=0\n",
    "    for i in range(n_trials*10):\n",
    "        scores = {}\n",
    "        # if i < 2:\n",
    "        scores['max_depth'] = trialsXGBoost.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "        scores['n_estimators'] = trialsXGBoost.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "        scores['learning_rate'] = trialsXGBoost.trials[i]['misc']['vals']['learning_rate'][0]+1\n",
    "        scores['subsample'] = trialsXGBoost.trials[i]['misc']['vals']['subsample'][0]+1\n",
    "        # scores['seed'] = trialsXGBoost.trials[i]['misc']['vals']['seed'][0]\n",
    "            # \n",
    "            # 'n_estimators'\n",
    "        for c in varStrings:\n",
    "            # print(c)\n",
    "            key = \"ATTACH::{}::{}\".format(i,c)\n",
    "            scores[c] = trialsXGBoost.attachments[key]\n",
    "            scores[\"i\"] = i\n",
    "        xgbValues.append(scores)\n",
    "    # print (scores)\n",
    "    trials_XGB_df = pd.DataFrame.from_dict(xgbValues)\n",
    "\n",
    "    rfValues = []\n",
    "    varStrings = [\"falsePositive\", \"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\",]\n",
    "    scores = {}\n",
    "    i=0\n",
    "    for i in range(n_trials):\n",
    "        scores = {}\n",
    "        # if i < 2:\n",
    "        # scores['max_depth'] = trialsRandomForest.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "        scores['n_estimators'] = trialsRandomForest.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "\n",
    "            # \n",
    "            # 'n_estimators'\n",
    "        for c in varStrings:\n",
    "            # print(c)\n",
    "            key = \"ATTACH::{}::{}\".format(i,c)\n",
    "            scores[c] = trialsRandomForest.attachments[key]\n",
    "            scores[\"i\"] = i\n",
    "        rfValues.append(scores)\n",
    "\n",
    "    trials_rf_df = pd.DataFrame.from_dict(rfValues)\n",
    "    \n",
    "    ObjectsToSaveRF = [best_model_RandomForest, best_model_XGBoost, all_cols, X_valid, y_valid,trials_rf_df,trials_XGB_df]\n",
    "\n",
    "    # timestr =  str(datetime.datetime.now().strftime('%Y_%m_%d'))\n",
    "    # Data_Storage_File = 'Results/GenMed_SepsisPathway_{}_{}_FeatureImportances.pkl'.format(DataSet,DiagnosisString)\n",
    "\n",
    "    Data_Storage_File = 'Results/Nov_2024_{}_{}_BestFit_Models_Pathway_ED.pkl'.format(DiagnosisString,DataSet)\n",
    "    print(Data_Storage_File)\n",
    "\n",
    "    with open(Data_Storage_File, 'wb') as file:  \n",
    "        pickle.dump(ObjectsToSaveRF, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 0.16248644728822462,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 29,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': 181,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': 55,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 0.8958502308437364,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialsXGBoost.results[1]['model'][1].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = np.concatenate([numeric_features])\n",
    "\n",
    "if len(categorical_features)>0:\n",
    "    new_cat_cols =best_model_RandomForest['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(categorical_features)\n",
    "    all_cols = np.concatenate([numeric_features,new_cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbValues = []\n",
    "varStrings = [\"falsePositive\",  \"threshold\",\"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\"]\n",
    "scores = {}\n",
    "i=0\n",
    "for i in range(n_trials*10):\n",
    "    scores = {}\n",
    "    # if i < 2:\n",
    "    scores['max_depth'] = trialsXGBoost.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "    scores['n_estimators'] = trialsXGBoost.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "    scores['learning_rate'] = trialsXGBoost.trials[i]['misc']['vals']['learning_rate'][0]+1\n",
    "    scores['subsample'] = trialsXGBoost.trials[i]['misc']['vals']['subsample'][0]+1\n",
    "    # scores['seed'] = trialsXGBoost.trials[i]['misc']['vals']['seed'][0]\n",
    "        # \n",
    "        # 'n_estimators'\n",
    "    for c in varStrings:\n",
    "        # print(c)\n",
    "        key = \"ATTACH::{}::{}\".format(i,c)\n",
    "        scores[c] = trialsXGBoost.attachments[key]\n",
    "        scores[\"i\"] = i\n",
    "    xgbValues.append(scores)\n",
    "# print (scores)\n",
    "trials_XGB_df = pd.DataFrame.from_dict(xgbValues)\n",
    "\n",
    "rfValues = []\n",
    "varStrings = [\"falsePositive\", \"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\",]\n",
    "scores = {}\n",
    "i=0\n",
    "for i in range(n_trials):\n",
    "    scores = {}\n",
    "    # if i < 2:\n",
    "    # scores['max_depth'] = trialsRandomForest.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "    scores['n_estimators'] = trialsRandomForest.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "\n",
    "        # \n",
    "        # 'n_estimators'\n",
    "    for c in varStrings:\n",
    "        # print(c)\n",
    "        key = \"ATTACH::{}::{}\".format(i,c)\n",
    "        scores[c] = trialsRandomForest.attachments[key]\n",
    "        scores[\"i\"] = i\n",
    "    rfValues.append(scores)\n",
    "\n",
    "trials_rf_df = pd.DataFrame.from_dict(rfValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results/Nov_2024_SepsisFlag_DataSet11_a_BestFit_Models_Pathway_ED.pkl\n"
     ]
    }
   ],
   "source": [
    "ObjectsToSaveRF = [best_model_RandomForest, best_model_XGBoost, all_cols, X_valid, y_valid,trials_rf_df,trials_XGB_df]\n",
    "\n",
    "# timestr =  str(datetime.datetime.now().strftime('%Y_%m_%d'))\n",
    "# Data_Storage_File = 'Results/GenMed_SepsisPathway_{}_{}_FeatureImportances.pkl'.format(DataSet,DiagnosisString)\n",
    "\n",
    "Data_Storage_File = 'Results/Nov_2024_{}_{}_BestFit_Models_Pathway_ED.pkl'.format(DiagnosisString,DataSet)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "with open(Data_Storage_File, 'wb') as file:  \n",
    "    pickle.dump(ObjectsToSaveRF, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceihml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
