{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Sepsis Pathway \n",
    "\n",
    "Setup Libraries and plotting defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "c:\\Users\\ibertr02\\venvs\\ceihml\\Lib\\site-packages\\snowflake\\connector\\options.py:103: UserWarning: You have an incompatible version of 'pyarrow' installed (15.0.2), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n",
      "Failed to import ArrowResult. No Apache Arrow result set format can be used. ImportError: DLL load failed while importing arrow_iterator: The specified procedure could not be found.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import statsmodels.formula.api as smf\n",
    "#from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from pandasql import sqldf\n",
    "import sqlalchemy\n",
    "import pyodbc\n",
    "\n",
    "import dfply as dfp\n",
    "from dfply import *\n",
    "\n",
    "import datetime\n",
    "from datetime import *\n",
    "\n",
    "import pyodbc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics         import balanced_accuracy_score, precision_score, classification_report\n",
    "from sklearn.metrics         import recall_score, f1_score, make_scorer, cohen_kappa_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import forestci as fci\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer, PowerTransformer\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, roc_auc_score, accuracy_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#from statsmodels.tools.tools import add_constant\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "n_est=55\n",
    "\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import Utilities\n",
    "import importlib\n",
    "importlib.reload(Utilities)\n",
    "\n",
    "import MLUtilities\n",
    "importlib.reload(MLUtilities)\n",
    "\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "plt.style.use('./CEIH.mplstyle')\n",
    "color_dict = {0: to_rgba('#32C0D2', 1),\n",
    "                1: to_rgba(\"#E0B165\", 1),}\n",
    "\n",
    "cmap_blended = sns.blend_palette([\"#ADE6ED\",\"#70D3E0\",\"#32C0D2\",\"#289AA8\",\"#307078\"], as_cmap=True)\n",
    "\n",
    "\n",
    "import math\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "    \n",
    "OtherValues = {'TriageCategory_2':'Triage Category 2', 'SoBFlag': 'Shortness of Breath', 'TriageCategory_4':'Triage Category 4',\n",
    "               'TriageCategory_1':'Triage Category 1', 'TriageCategory_5':'Triage Category 5', 'TriageCategory_3':'Triage Category 3',\n",
    "             'FirstGCSScoreAdult':'Glasgow Coma Scale',\n",
    "               'FirstUrinalysisBlood': 'Urinalysis Blood', 'IndigenousStatusDescription_Not Aboriginal-TSI':  'Non Indiginous',\n",
    "               'IndigenousStatusDescription_Not Stated':  'Indiginous Status not stated', 'FirstUrinalysisLeukocytes':'Urinalysis Leukocytes',\n",
    "               'FirstPulseRateBPM':'Pulse Rate', 'FirstRespiration':'Respiration Rate', 'FirstSpO2':'O2 Saturation (%)',  'Gender_Male':'Sex - Male',\n",
    "               'FirstLevelofConsciousness':'Level of Consciousness', 'IndigenousStatusDescription_Aboriginal and TSI':'Aboriginal and TSI',\n",
    "               'IndigenousStatusDescription_TSI':'TSI','Gender_Indeterminate':'Sex - Indeterminate', 'Gender_Unknown':'Sex - Unknown',\n",
    "               'FirstO2Flow':'O2 Flow '\n",
    "               }\n",
    "\n",
    "\n",
    "plotSettings = {\n",
    "        #  ( bins, xmin, xmax, log/linear)\n",
    "        'AGEONADMISSION':(50,20,110,'linear','Age (y)', False, 0,0),\n",
    "        \n",
    "        \n",
    "        'FirstBloodGlucose':(50,0,100,'log','Blood Glucose [mmol/L]', False,0, 0),\n",
    "        'FirstTemperatureDegreesC':(50,30,45,'log', r\"Temperature [$^\\circ$C]\", True,35.5,38.1),\n",
    "                'FirstWeightKg':(50,50,150,'log','Weight [kg]', False, 0,0),\n",
    "\n",
    "        \n",
    "        'FirstPainAssessment': (11,-0.5,10.5,'log','Pain Assessment', False, 0,0),\n",
    "        'FirstBPSystolic': (50,50,250,'log', 'BP Systolic [mm Hg]',True, 100,170 ),\n",
    "        'FirstBPDiastolic': (50,0,200,'log', 'BP Diastolic [mm Hg]', False,0,0),\n",
    "        'FirstEstimatedGlomerularFiltrationRate': (50,0,100,'log',r\"Estimated Glomerular Filtration Rate [mL/min/1.73m$^{2}$]\", True, 60, 100),\n",
    "        'FirstCreatinine': (50,0,800,'log',r\"Creatinine - Serum [$\\mu$mol/L]\", True, 45, 110),\n",
    "        'FirstAlbumin': (60,0,60,'log','Albumin  Level [g/L]', True, 30, 48),\n",
    "        'FirstTotalBilirubin': (60,0,100,'log',r\"Total Bilirubin Level [$\\mu$mol/L]\", True, 2, 24 ),\n",
    "        'FirstAlkalinePhosphatase': (60,0,800,'log','Alkaline Phosphatase Level [U/L]',True, 30,110),\n",
    "        'FirstAlanineAminotransferase': (60,0,700,'log','Alanine Aminotransferase Level [U/L]', True,0,55),\n",
    "        'FirstAspartateAminotransferase': (60,0,700,'log','Aspartate Aminotransferase Level [U/L]', True, 0,45),\n",
    "        'FirstGammaGlutamylTransferase': (60,0,700,'log','Gamma Glutamyl Transferase Level [U/L]', True, 0, 60),\n",
    "        'FirstLactateDehydrogenase': (60,0,1200,'log','Lactate Dehydrogenase [U/L]', True, 120, 250),\n",
    "        'FirstHaemoglobin': (50,10, 220,'log','Haemoglobin [g/L]', True, 115, 175),\n",
    "        'FirstWhiteCellCount': (50,0, 50,'log',r\"White Cell Count [$\\times 10^{9}$/L]\",True, 4,11),\n",
    "        'FirstPlateletCount': (50,0, 1000,'log',r\"Platelet Count [$\\times 10^{9}$/L]\",True,150,500),\n",
    "        'FirstNeutrophils': (50,0, 50,'log',r\"Absolute Neutrophil Count [$\\times 10^{9}$/L]\",True,1.80,7.50),\n",
    "        'FirstDDimer': (40,0, 20,'log',r\"D-Dimer [mg/L]\",True,0,0.79),\n",
    "        'FirstCreactiveprotein': (50,0, 600,'log',r\"C-Reactive Protein [mg/L]\",True, 0,8),\n",
    "        'FirstTroponinT': (50,0, 600,'log',r\"Troponin T Level [mg/L]\",True,0,16),\n",
    "        'FirstNTproBNP': (50,0, 40000,'log',r\"NT-pro Brain Natriuretic Peptide [mg/L]\",True,0,124),\n",
    "        \n",
    "        'FirstAnionGapVenous': (50,0, 50,'log',r\"Anion Gap Venous [mmol/L]\", True, 7, 17),\n",
    "        'FirstAnionGapArterial': (50,0, 50,'log',r\"Anion Gap Arterial [mmol/L]\",  True, 7, 17),\n",
    "        'FirstBaseExcessVenous': (50,-30, 30,'log',r\"Base Excess Venous [mmol/L]\", True, -3, 3),\n",
    "        'FirstBaseExcessArterial': (50,-30, 30,'log',r\"Base Excess Arterial [mmol/L]\", True, -3, 3),\n",
    "        'FirstBilirubinVenous': (60,0, 60,'log',r\"Bilirubin Venous [$\\mu$mol/L]\", True, 2,24),\n",
    "        'FirstBilirubinArterial': (60,0, 60,'log',r\"Bilirubin Arterial [$\\mu$mol/L]\", True, 2,24),\n",
    "        'FirstCarboxyhaemoglobinVenous': (50,0, 20,'log',r\"Carboxyhaemoglobin Venous [%]\", True, 0.3, 1.8),\n",
    "        'FirstCarboxyhaemoglobinArterial': (50,0, 20,'log',r\"Carboxyhaemoglobin Arterial [%]\", True, 0.3, 1.8),\n",
    "        'FirstChlorideDirectVenous': (50,50, 150,'log',r\"Chloride Direct Venous [mmol/L]\",False, 100,109),\n",
    "        'FirstChlorideDirectArterial': (50,50, 150,'log',r\"Chloride Direct Arterial [mmol/L]\", True, 100,109),\n",
    "        'FirstCreatinineVenous':(50,0,500,'log',r\"Creatinine Venous [$\\mu$mol/L]\", True, 50, 120),\n",
    "        'FirstCreatinineArterial':(50,0,500,'log',r\"Creatinine Arterial [$\\mu$mol/L]\", True, 50,120),\n",
    "        'FirstGlucoseVenous':(50,0,30,'log',r\"Glucose  Venous [mmol/L]\", False,0,0),\n",
    "        'FirstGlucoseArterial':(50,0,30,'log',r\"Glucose  Arterial [mmol/L]\", True,2.6,5.6),\n",
    "        'FirstIonised Calcium Venous':(50,0,2,'log',r\"Ionised Calcium Venous [mmol/L]\", True, 1.1, 1.3),\n",
    "        'FirstIonised Calcium Arterial':(50,0,2,'log',r\"Ionised Calcium Arterial [mmol/L]\", True, 1.1, 1.3),\n",
    "        'FirstLactateVenous':(50,0,30,'log',r\"Lactate Venous [mmol/L]\", True, 0.2, 2.0),\n",
    "        'FirstLactateArterial':(50,0,30,'log',r\"Lactate Arterial [mmol/L]\", True, 0.2, 2.0),\n",
    "        'FirstMethaemoglobinVenous': (20,0, 3,'log',r\"Methaemoglobin Venous [%]\", True, 0.4, 1.2),\n",
    "        'FirstMethaemoglobinArterial': (20,0, 3,'log',r\"Methaemoglobin Arterial [%]\", True, 0.2,0.6),\n",
    "        'FirstOxygenSaturationVenous': (50,0, 100,'log',r\"Oxygen Saturation Venous [%]\", False, 0,0),\n",
    "        'FirstOxygenSaturationArterial': (50,0, 100,'log',r\"Oxygen Saturation Arterial [%]\", True,95, 99),\n",
    "        'FirstOxyhaemoglobinVenous': (50,0, 100,'log',r\"Oxyhaemoglobin Venous [%]\", False, 0,0),\n",
    "        'FirstOxyhaemoglobinArterial': (50,0, 100,'log',r\"Oxyhaemoglobin Arterial [%]\", False, 0,0),\n",
    "        'FirstReducedHaemoglobinVenous': (50,0, 100,'log',r\"Reduced Haemoglobin Venous [%]\", False, 0,0),\n",
    "        'FirstReducedHaemoglobinArterial': (50,0, 100,'log',r\"Reduced Haemoglobin Arterial [%]\", False, 0,0),\n",
    "        'FirstTotalHaemoglobinVenous': (50,10, 220,'log','Total Haemoglobin Venous [g/L]', True, 115,180),\n",
    "        'FirstTotalHaemoglobinArterial': (50,10, 220,'log','Total Haemoglobin Arterial [g/L]', True, 115,180), \n",
    "        'FirstpCO2Venous': (50,0,150,'log', 'pCO2 Venous [mm Hg]', True,41,51),\n",
    "        'FirstpCO2Arterial': (50,0,150,'log', 'pCO2 Arterial [mm Hg]', True, 35, 45 ),\n",
    "        'FirstpO2Venous': (50,0,200,'log', 'pO2 Venous [mm Hg]', True, 25,40),\n",
    "        'FirstpO2Arterial': (50,0,200,'log', 'pO2 Arterial [mm Hg]', True,67, 108),\n",
    "        'FirstpHVenous': (50,6.8,7.8,'log', 'pH Venous', True, 7.32,7.42),\n",
    "        'FirstpHArterial': (50,6.8,7.8,'log', 'pH Arterial', True, 7.36, 7.44),\n",
    "        'FirstPotassiumDirectVenous':(50,0,10,'log',r\"Potassium Direct Venous [mmol/L]\", False, 0,0),\n",
    "        'FirstPotassiumDirectArterial':(50,0,10,'log',r\"Potassium Direct Arterial [mmol/L]\", True, 3.1, 4.2),\n",
    "        'FirstSodiumDirectVenous':(50,100,180,'log',r\"Sodium Direct Venous [mmol/L]\", False, 0,0),\n",
    "        'FirstSodiumDirectArterial':(50,100,180,'log',r\"Sodium Direct Arterial [mmol/L]\", True, 137, 145),}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for Machine Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepsis SepsisFlag\n"
     ]
    }
   ],
   "source": [
    "# Sepsis HeartFailure PE Pneumonia COPD UTI\n",
    "# SepsisPneumonia\n",
    "Diagnosis =   \"Sepsis\"\n",
    "# Diagnosis = 'SepsisPneumonia'\n",
    "\n",
    "DiagnosisString=Diagnosis+'Flag'\n",
    "\n",
    "# DataSet1 All observations \n",
    "# DataSet2 Not including Oxygen Flow \n",
    "\n",
    "DataSet = 'DataSet40' \n",
    "\n",
    "\n",
    "# MLModel = 'randomforest'\n",
    "\n",
    "print(Diagnosis,DiagnosisString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date =  '2023-01-01'  #dates[Facility][0]\n",
    "end_date   =  '2024-01-01' #dates[Facility][1]\n",
    "\n",
    "select_start_date = '2023-01-01'\n",
    "\n",
    "DataReasons = \"Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_2023-01-01_2024-01-01_Training_Stage_01.pkl\n"
     ]
    }
   ],
   "source": [
    "Data_Storage_File = 'DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_{}_{}_{}_Stage_01.pkl'.format(start_date,end_date,DataReasons)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "\n",
    "with open(Data_Storage_File, 'rb') as file:\n",
    "    Emergency_IPInfo_Complete_Numeric = pd.read_pickle(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(MLUtilities)\n",
    "Emergency_IPInfo_Complete_Numeric = MLUtilities.setNumeric(Emergency_IPInfo_Complete_Numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emergency_IPInfo_Complete_Numeric['IndiginousFlag'] = 0  # np.where((Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isna()|Emergency_IPInfo_Complete_Numeric.IndiginousStatus=='Not Aboriginal-TSI'),0,1)\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isin(['Aboriginal','Aboriginal and TSI', 'TSI']),'IndiginousFlag'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Machine Learning Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis being investigated = SepsisFlag\n",
      "Total Number of Cases = 320013\n",
      "Number of SepsisFlag Cases  2761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DiagnosisString='SepsisFlag'\n",
    "\n",
    "if Diagnosis == \"SepsisPneumonia\":\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric.SepsisFlag==1)|(Emergency_IPInfo_Complete_Numeric.PneumoniaFlag==1), DiagnosisString] = 1\n",
    "\n",
    "print(\"Diagnosis being investigated = {}\".format(DiagnosisString))\n",
    "print(\"Total Number of Cases = {}\".format(len(Emergency_IPInfo_Complete_Numeric.index)))\n",
    "print(\"Number of {} Cases \".format(DiagnosisString),len(Emergency_IPInfo_Complete_Numeric[Emergency_IPInfo_Complete_Numeric[DiagnosisString]==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(0,17),'age_range']='0-17'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(18,33),'age_range']='18-33'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(34,48),'age_range']='34-48'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(49,64),'age_range']='49-64'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(65,78),'age_range']='65-78'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(79,98),'age_range']='79-98'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(98,120),'age_range']='98+'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(121,200),'age_range']='Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FirstGammaGlutamylTransferase\n",
      "FirstBloodGlucose\n",
      "FirstBPDiastolic\n",
      "FirstBPSystolic\n",
      "FirstGCSScoreAdult\n",
      "FirstLevelofConsciousness\n",
      "FirstO2Flow\n",
      "FirstPulseRateBPM\n",
      "FirstRespiration\n",
      "FirstSpO2\n",
      "FirstTemperatureDegreesC\n",
      "FirstUrinalysisBlood\n",
      "FirstUrinalysisLeukocytes\n",
      "FirstEstimatedGlomerularFiltrationRate\n",
      "FirstAlbumin\n",
      "FirstTotalBilirubin\n",
      "FirstAlkalinePhosphatase\n",
      "FirstAlanineAminotransferase\n",
      "FirstAspartateAminotransferase\n",
      "FirstLactateDehydrogenase\n",
      "FirstHaemoglobin\n",
      "FirstWhiteCellCount\n",
      "FirstPlateletCount\n",
      "FirstNeutrophils\n",
      "FirstDDimer\n",
      "FirstCreactiveprotein\n",
      "FirstTroponinT\n",
      "FirstNTproBNP\n",
      "TRIAGE_CATEGORY\n"
     ]
    }
   ],
   "source": [
    "df = Emergency_IPInfo_Complete_Numeric.copy()\n",
    "df.name='{} diagnosis detected from full Diagnosis list, updated'.format(Diagnosis)\n",
    "importlib.reload(MLUtilities)\n",
    "df = MLUtilities.setDefaults(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnalysisVariable =['FirstBPSystolic', 'FirstLevelofConsciousness',\n",
    "       'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2',\n",
    "       'FirstTemperatureDegreesC',  #'FirstWeightKg', 'FirstUrinalysisBlood',\n",
    "       # 'FirstUrinalysisLeukocytes', \n",
    "       #'FirstO2Flow',\n",
    "       #'FirstGCSScoreAdult',\n",
    "       DiagnosisString]\n",
    "\n",
    "if DataSet == 'DataSet1':\n",
    "       AnalysisVariable.append('FirstO2Flow')\n",
    "\n",
    "if DataSet == 'DataSet30':\n",
    "       AnalysisVariable.append('IndiginousStatus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df[AnalysisVariable].copy()\n",
    "# df_temp[DiagnosisString] = df_temp[DiagnosisString].astype('category')\n",
    "# df_temp['TriageCategory'] = df_temp['TriageCategory'].astype('category')\n",
    "# df_temp['Gender'] = df_temp['Gender'].astype('category')\n",
    "# df_temp['IndigenousStatusDescription'] = df_temp['IndigenousStatusDescription'].astype('category')                           \n",
    "# df_temp['SoBFlag'] = df_temp['SoBFlag'].astype('category')\n",
    "# df_temp.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[df_temp.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_temp[[DiagnosisString]]\n",
    "X = df_temp[AnalysisVariable].drop(DiagnosisString, axis=1).copy()\n",
    "x_vars = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only have numerical features in this model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_vars = []\n",
    "\n",
    "numeric_features = X.drop(skew_vars, axis=1).select_dtypes(\n",
    "        include=['float64', 'int64']).columns\n",
    "\n",
    "categorical_features = X.select_dtypes(\n",
    "        include=['category', 'object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features,numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler()),  # StandardScaler #MinMaxScaler\n",
    "        #('skew', FunctionTransformer(log_transform))\n",
    "    ])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))])  # OrdinalEncoder() #OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "def pip_f(reg):\n",
    "    pip = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', reg)\n",
    "    ])\n",
    "    return(pip)\n",
    "\n",
    "functions = {\n",
    "        # 'decisiontree': DecisionTreeClassifier(class_weight='balanced', random_state=n_est),   #######class_weight='balanced' check this\n",
    "        'randomforest': RandomForestClassifier(class_weight='balanced', random_state=n_est),\n",
    "        # 'knn': KNeighborsClassifier(),\n",
    "        # 'xgboost':xgb.XGBClassifier (class_weight='balanced', random_state=n_est)\n",
    "        'xgboost':xgb.XGBClassifier ( random_state=n_est) # class_weight='balanced' not in xgboost??\n",
    "    }\n",
    "\n",
    "key = 'randomforest'\n",
    "best_performance = {}\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name='Sepsis diagnosis detected from full Diagnosis list, updated'\n",
    "\n",
    "print(df.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = {}\n",
    "for key, value in functions.items():\n",
    "    print(key)\n",
    "    mod=pip_f(value)\n",
    "    mod.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "    y_preds=mod.predict (X_valid) \n",
    "    y_preds_proba=mod.predict_proba (X_valid) \n",
    "\n",
    "    y2=np.ravel(y_valid,order='c')\n",
    "\n",
    "    yprobs = np.delete(y_preds_proba,[0],1)\n",
    "    yprobs2 = np.ravel(yprobs,order='c') \n",
    "\n",
    "    fit_result[\"{a} _ {b}\".format(a=key,  b=np.where(df.name==df.name, str(df.name)+': having any Dx',\n",
    "                                                    str(df.name)))]=roc_auc_score(y2, yprobs, multi_class=\"ovr\", average=\"weighted\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit_result[\"{a} _ {b}\".format(a=key,  b=np.where(df.name==df.name, str(df.name)+': having any Dx',\n",
    "#                                                 str(df.name)))]=roc_auc_score(y2, yprobs, multi_class=\"ovr\", average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "    \n",
    "\n",
    "\n",
    "space4xgb = {\n",
    "    'seed': n_est,\n",
    "    'objective': 'multi:softproba',\n",
    "    'class_weight': 'balanced',\n",
    "    'max_depth': hp.choice('max_depth', np.arange(1, 14, 1, dtype=int)),\n",
    "    'gamma': hp.uniform('gamma', 1, 9),\n",
    "    'reg_alpha': hp.choice('reg_alpha', np.arange(40, 180, 1, dtype=int)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(0, 10, 1, dtype=int)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(20, 200, 1, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', 0.01, 1),\n",
    "}\n",
    "\n",
    "space4xgbsepsis = {\n",
    "    'random_state': n_est, \n",
    "    'max_depth': hp.choice('max_depth', np.arange(1,30, 1, dtype=int)), \n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(20, 200, 1, dtype=int))\n",
    "     }\n",
    "\n",
    "\n",
    "space4rf = {\n",
    "    'random_state': n_est,\n",
    "    'class_weight': 'balanced',\n",
    "    'max_depth':  None, #    hp.choice('max_depth', np.arange(5, 30, 1, dtype=int)),\n",
    "    #'max_features':    #hp.choice('max_features', np.arange(2, 10, 1, dtype=int)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(100, 500, 10, dtype=int))\n",
    "}\n",
    "\n",
    "\n",
    "def hyperparameter_tuning_rf_sepsis(trial_params):\n",
    "        \n",
    "    classifier = RandomForestClassifier(**trial_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", classifier)\n",
    "        ])\n",
    "    model.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "    predictions_valid = model.predict_proba(X_valid)\n",
    "    ypreds = np.delete(predictions_valid,[0],1)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold = thresholds[idx]\n",
    "    false_positive = fpr[idx]\n",
    "    # redo predictions with new threshold \n",
    "    y_select_2 = np.where(ypreds<thresholds[idx],0,1)\n",
    "\n",
    "    auc_score = roc_auc_score(y_valid, yprobs, multi_class=\"ovr\", average=\"weighted\")\n",
    "    accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "    balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "    recall  =recall_score(y_valid, y_select_2)\n",
    "    precision = precision_score(y_valid, y_select_2)\n",
    "    f1 = f1_score(y_valid, y_select_2)\n",
    "\n",
    "    scores = {\"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score}\n",
    "\n",
    "    return {'status': STATUS_OK, 'loss': -recall, 'model': model, 'attachments':scores}\n",
    "\n",
    "\n",
    "def hyperparameter_tuning_xgb_sepsis(trial_params):\n",
    "            \n",
    "    classifier = xgb.XGBClassifier(**trial_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", classifier)\n",
    "        ])\n",
    "    \n",
    "    model.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "    predictions_valid = model.predict_proba(X_valid)\n",
    "    ypreds = np.delete(predictions_valid,[0],1)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold = thresholds[idx]\n",
    "    false_positive = fpr[idx]\n",
    "    # redo predictions with new threshold \n",
    "    y_select_2 = np.where(ypreds<thresholds[idx],0,1)\n",
    "\n",
    "    auc_score = roc_auc_score(y_valid, yprobs, multi_class=\"ovr\", average=\"weighted\")\n",
    "    accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "    balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "    recall  =recall_score(y_valid, y_select_2)\n",
    "    precision = precision_score(y_valid, y_select_2)\n",
    "    f1 = f1_score(y_valid, y_select_2)\n",
    "\n",
    "    scores = {\"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score}\n",
    "\n",
    "    return {'status': STATUS_OK, 'loss': -recall, 'model': model, 'attachments':scores}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 100\n",
    "\n",
    "trialsRandomForest = Trials()\n",
    "# trialsXGBoost = Trials()\n",
    "\n",
    "\n",
    "# best_params_XGB = fmin(fn = hyperparameter_tuning_xgb_sepsis,\n",
    "#                     space = space4xgbsepsis,\n",
    "#                     algo = tpe.suggest,\n",
    "#                     max_evals = n_trials, \n",
    "#                     trials = trialsXGBoost\n",
    "#                     )\n",
    "\n",
    "best_params_RandomForest = fmin(fn=hyperparameter_tuning_rf_sepsis,\n",
    "                       space=space4rf,\n",
    "                       algo=tpe.suggest,\n",
    "                       max_evals=n_trials,\n",
    "                       trials=trialsRandomForest\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'randomforest'\n",
    "\n",
    "mod=pip_f(value)\n",
    "mod.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "y_preds=mod.predict (X_valid) \n",
    "y_preds_proba=mod.predict_proba (X_valid) \n",
    "\n",
    "y2=np.ravel(y_valid,order='c')\n",
    "\n",
    "yprobs = np.delete(y_preds_proba,[0],1)\n",
    "yprobs2 = np.ravel(yprobs,order='c') \n",
    "\n",
    "roc = roc_auc_score(y2, yprobs, multi_class=\"ovr\", average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreRandomForest =  roc_auc_score(y2, yprobs, multi_class=\"ovr\", average=\"weighted\") # [t['result']['loss'] for t in trialsRandomForest.trials]\n",
    "best_model_RandomForest=mod #   trialsRandomForest.results[np.argmin([r['loss'] for r in trialsRandomForest.results])]['model']\n",
    "\n",
    "# scoreRandomForest =  [t['result']['loss'] for t in trialsRandomForest.trials]\n",
    "# best_model_RandomForest=trialsRandomForest.results[np.argmin([r['loss'] for r in trialsRandomForest.results])]['model']\n",
    "\n",
    "\n",
    "scoreXGBoost = [t['result']['loss'] for t in trialsXGBoost.trials]\n",
    "best_model_XGBoost=trialsXGBoost.results[np.argmin([r['loss'] for r in trialsXGBoost.results])]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cat_cols =best_model_RandomForest['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(categorical_features)\n",
    "all_cols = np.concatenate([numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ObjectsToSaveRF = [best_model_RandomForest, best_model_XGBoost, all_cols, X_valid, y_valid]\n",
    "\n",
    "# timestr =  str(datetime.datetime.now().strftime('%Y_%m_%d'))\n",
    "# Data_Storage_File = 'Results/GenMed_SepsisPathway_{}_{}_FeatureImportances.pkl'.format(DataSet,DiagnosisString)\n",
    "\n",
    "Data_Storage_File = 'Results/{}_{}_BestFit_Models_Pathway_ED.pkl'.format(DiagnosisString,DataSet)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "with open(Data_Storage_File, 'wb') as file:  \n",
    "    pickle.dump(ObjectsToSaveRF, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpString =  'Random Forest'\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "best_model = best_model_RandomForest\n",
    "\n",
    "y_preds=best_model.predict (X_valid)\n",
    "\n",
    "y_preds_proba=best_model.predict_proba (X_valid)\n",
    "# select positive class \n",
    "yprobs = np.delete(y_preds_proba,[0],1)\n",
    "yprobs2 = np.ravel(yprobs,order='c') \n",
    "\n",
    "y2=np.ravel(y_valid,order='c')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, yprobs)\n",
    "val,idx = find_nearest(tpr,0.85)\n",
    "# print(val,tpr[idx],fpr[idx],thresholds[idx])\n",
    "\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, yprobs)\n",
    "auc = roc_auc_score(y_valid, yprobs)\n",
    "plt.plot(fpr,tpr,label=\"{} (RF), area= {:.3f}\".format(Diagnosis,auc))\n",
    "\n",
    "\n",
    "x = np.arange(0,1,0.01)\n",
    "plt.plot(x,x,label='chance (auc=0.5)',color='k',linestyle='--')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(\"Figures/{}_{}_AUC_Plot.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "\n",
    "val,idx = find_nearest(tpr,0.85)\n",
    "print(tpr[idx],fpr[idx],thresholds[idx])\n",
    "print(len(tpr))\n",
    "\n",
    "yprobs2 = np.ravel(yprobs,order='c') \n",
    "\n",
    "compareResults = pd.DataFrame({DiagnosisString:y2, \"Prob\":yprobs2})\n",
    "compareResults.describe()\n",
    "\n",
    "\n",
    "ResultsFlag0 = compareResults.loc[compareResults[DiagnosisString]==0]\n",
    "ResultsFlag1 = compareResults.loc[compareResults[DiagnosisString]==1]\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "sns.histplot(data=ResultsFlag0, x=\"Prob\",  binrange=[0.,1.], binwidth=0.025, stat = 'probability', label='Not {}'.format(Diagnosis))\n",
    "sns.histplot(data=ResultsFlag1, x=\"Prob\",  binrange=[0.,1.], binwidth=0.025,  stat = 'probability', color= \"#E0B165\" , label='{}'.format(Diagnosis))\n",
    "plt.legend(loc=1, title=\"{}\".format(tmpString))\n",
    "\n",
    "y = np.arange(0.,ax.get_ylim()[1],0.01)\n",
    "# print(len(y))\n",
    "x =  np.full(shape = len(y), fill_value = thresholds[idx])\n",
    "\n",
    "plt.plot(x,y,label='chance (auc=0.5)',color='k',linestyle='--')\n",
    "plt.ylabel(\"Fraction\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.savefig(\"Figures/{}_{}_Score_Plot.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "\n",
    "yprobslog2 = np.log(yprobs2) \n",
    "\n",
    "compareResultsLog = pd.DataFrame({'SepsisFlag':y2, \"Prob\":yprobslog2})\n",
    "#print(compareResultsLog.describe())\n",
    "\n",
    "\n",
    "ResultsFlag0_xgb_log = compareResultsLog.loc[compareResultsLog.SepsisFlag==0]\n",
    "ResultsFlag1_xgb_log = compareResultsLog.loc[compareResultsLog.SepsisFlag==1]\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "sns.histplot(data=ResultsFlag0_xgb_log, x=\"Prob\",  binrange=[-8,0.], binwidth=0.25, stat = 'probability',label='Not {}'.format(Diagnosis))\n",
    "sns.histplot(data=ResultsFlag1_xgb_log, x=\"Prob\",  binrange=[-8,0.], binwidth=0.25,  stat = 'probability',  color= \"#E0B165\" , label='{}'.format(Diagnosis))\n",
    "plt.legend(loc=2,  title=\"XG Boost\")\n",
    "plt.ylabel(\"Fraction\")\n",
    "\n",
    "y = np.arange(0.,ax.get_ylim()[1],0.01)\n",
    "#print(len(y))\n",
    "x =  np.full(shape = len(y), fill_value = np.log(thresholds[idx]))\n",
    "\n",
    "plt.plot(x,y,label='chance (auc=0.5)',color='k',linestyle='--')\n",
    "plt.ylabel(\"Fraction\")\n",
    "plt.xlabel(\"ln(Score)\")\n",
    "\n",
    "\n",
    "y_preds2 = np.where(yprobs2<thresholds[idx],0,1)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(7, 7))\n",
    "cmp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_valid, y_preds2, normalize='true')\n",
    "    )\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "cmp.plot(cmap=cmap_blended, ax=ax, text_kw={'fontsize':'x-large'})\n",
    "ax.grid(False)\n",
    "\n",
    "plt.savefig(\"Figures/{}_{}_Confusion_Matrix_Plot.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# skew_vars=[]\n",
    "# numeric_features = X_valid.drop(skew_vars, axis=1).select_dtypes(include=['float64', 'int64']).columns #.columns.drop('diagnosis_count')\n",
    "# categorical_features = X_valid.select_dtypes(include=['category', 'object']).columns\n",
    "# # print (numeric_features)\n",
    "# new_cat_cols = best_model['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(categorical_features)\n",
    "# all_cols = np.concatenate([numeric_features, new_cat_cols])\n",
    "# print(all_cols)\n",
    "best_model[1].feature_importances_\n",
    "feat_importances=pd.Series(best_model[1].feature_importances_ , index=all_cols)\n",
    "feat_importances=pd.DataFrame(feat_importances).reset_index()\n",
    "\n",
    "feat_importances.columns=['feature', 'feature_importance']\n",
    "\n",
    "\n",
    "\n",
    "feat_importances.sort_values('feature_importance', ascending=False, inplace=True)\n",
    "\n",
    "feat_importances['name'] = None\n",
    "idx = feat_importances.index\n",
    "\n",
    "\n",
    "OtherValues = {'TriageCategory_2':'Triage Category 2', 'SoBFlag': 'Shortness of Breath', 'TriageCategory_4':'Triage Category 4',\n",
    "               'TriageCategory_1':'Triage Category 1', 'TriageCategory_5':'Triage Category 5', 'TriageCategory_3':'Triage Category 3',\n",
    "             'FirstGCSScoreAdult':'Glasgow Coma Scale',\n",
    "               'FirstUrinalysisBlood': 'Urinalysis Blood', 'IndigenousStatusDescription_Not Aboriginal-TSI':  'Non Indiginous',\n",
    "               'IndigenousStatusDescription_Not Stated':  'Indiginous Status not stated', 'FirstUrinalysisLeukocytes':'Urinalysis Leukocytes',\n",
    "               'FirstPulseRateBPM':'Pulse Rate', 'FirstRespiration':'Respiration Rate', 'FirstSpO2':r'O$_{2}$ Saturation (%)',  'Gender_Male':'Sex - Male',\n",
    "               'FirstLevelofConsciousness':'Level of Consciousness', 'IndigenousStatusDescription_Aboriginal and TSI':'Aboriginal and TSI',\n",
    "               'IndigenousStatusDescription_TSI':'TSI','Gender_Indeterminate':'Sex - Indeterminate', 'Gender_Unknown':'Sex - Unknown',\n",
    "               'FirstO2Flow':r'O$_{2}$ Flow '\n",
    "               }\n",
    "\n",
    "\n",
    "for i in idx:\n",
    "    # print(i)\n",
    "\n",
    "    val = feat_importances.loc[i].feature\n",
    "    # print(i,val)\n",
    "    try:\n",
    "        tmpValue = plotSettings[val][4]\n",
    "        feat_importances.at[i,'name']= tmpValue[0:tmpValue.rfind(' [')]\n",
    "    except: \n",
    "        for item9 in OtherValues.keys():\n",
    "            if val == item9:\n",
    "                feat_importances.at[i,'name'] = OtherValues[item9]\n",
    "        \n",
    "        # if val == 'TriageCategory_2':\n",
    "        #     feat_importances.at[i,'name']= 'Triage Category 2'\n",
    "        # else:\n",
    "        #     print(val)\n",
    "# print(feat_importances)\n",
    "\n",
    "feat_importances15=feat_importances.head(15)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "#plt.figure(figsize=(10,5))\n",
    "chart=sns.barplot(x='feature', y='feature_importance', data=feat_importances15, \n",
    "                    order=feat_importances15.sort_values('feature_importance', ascending=False).feature, ax=ax\n",
    ") #color='b')\n",
    "\n",
    "# print(chart.get_xticklabels())\n",
    "# chart.set_xticklabels(chart.get_xticklabels(),rotation=90, \n",
    "#                     horizontalalignment='right',fontweight='light', fontsize='x-large')\n",
    "\n",
    "chart.set_xticklabels( list(feat_importances15['name'].values),\n",
    "                      rotation=90, ha=\"center\",\n",
    "                   fontweight='light', fontsize='x-large')\n",
    "# plt.title(\"feature Importance: {a} {b}\".format(a=key,  b=str(\"Stuff\")+': having All Dx'))\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "chart.set(xlabel=None)\n",
    "\n",
    "ax.annotate('{}'.format(tmpString), xy=(0.95, 0.95), xycoords='axes fraction',\n",
    "            fontsize='x-large', ha='right', va='top')\n",
    "            #size=14, \n",
    "            # ha='right', va='top',\n",
    "            #bbox=dict(boxstyle='round', fc='w'))\n",
    "plt.savefig(\"Figures/{}_{}_Feature_Importance.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()\n",
    "feat_importances_RF = feat_importances.copy()  #.iloc #.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances_RF #.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpString =  'XG Boost'\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "best_model = best_model_XGBoost\n",
    "\n",
    "y_preds=best_model.predict (X_valid)\n",
    "\n",
    "y_preds_proba=best_model.predict_proba (X_valid)\n",
    "# select positive class \n",
    "yprobs = np.delete(y_preds_proba,[0],1)\n",
    "yprobs2 = np.ravel(yprobs,order='c') \n",
    "\n",
    "y2=np.ravel(y_valid,order='c')\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, yprobs)\n",
    "val,idx = find_nearest(tpr,0.85)\n",
    "print(val,tpr[idx],fpr[idx],thresholds[idx])\n",
    "\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, yprobs)\n",
    "auc = roc_auc_score(y_valid, yprobs)\n",
    "plt.plot(fpr,tpr,label=\"{} (XGB), area= {:.3f}\".format(Diagnosis,auc))\n",
    "\n",
    "\n",
    "x = np.arange(0,1,0.01)\n",
    "plt.plot(x,x,label='chance (auc=0.5)',color='k',linestyle='--')\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(\"Figures/{}_{}_AUC_Plot.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import math\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "\n",
    "val,idx = find_nearest(tpr,0.85)\n",
    "print(tpr[idx],fpr[idx],thresholds[idx])\n",
    "print(len(tpr))\n",
    "\n",
    "yprobs2 = np.ravel(yprobs,order='c') \n",
    "\n",
    "compareResults = pd.DataFrame({DiagnosisString:y2, \"Prob\":yprobs2})\n",
    "compareResults.describe()\n",
    "\n",
    "\n",
    "ResultsFlag0 = compareResults.loc[compareResults[DiagnosisString]==0]\n",
    "ResultsFlag1 = compareResults.loc[compareResults[DiagnosisString]==1]\n",
    "\n",
    "# sns.histplot(data=ResultsFlag0, x=\"Prob\",  binrange=[0.,1.], binwidth=0.025, stat = 'probability', label='Not {}'.format(Diagnosis))\n",
    "# sns.histplot(data=ResultsFlag1, x=\"Prob\",  binrange=[0.,1.], binwidth=0.025,  stat = 'probability', color= \"#E0B165\" , label='{}'.format(Diagnosis))\n",
    "# plt.legend(loc=1, title=\"{}\".format(tmpString))\n",
    "\n",
    "# y = np.arange(0.,0.2,0.01)\n",
    "# print(len(y))\n",
    "# x =  np.full(shape = len(y), fill_value = thresholds[idx])\n",
    "\n",
    "# plt.plot(x,y,label='chance (auc=0.5)',color='k',linestyle='--')\n",
    "# plt.ylabel(\"Fraction\")\n",
    "# plt.xlabel(\"Score\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "yprobslog2 = np.log(yprobs2) \n",
    "\n",
    "compareResultsLog = pd.DataFrame({'SepsisFlag':y2, \"Prob\":yprobslog2})\n",
    "#print(compareResultsLog.describe())\n",
    "\n",
    "\n",
    "ResultsFlag0_xgb_log = compareResultsLog.loc[compareResultsLog.SepsisFlag==0]\n",
    "ResultsFlag1_xgb_log = compareResultsLog.loc[compareResultsLog.SepsisFlag==1]\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "sns.histplot(data=ResultsFlag0_xgb_log, x=\"Prob\",  binrange=[-8,0.], binwidth=0.25, stat = 'probability',label='Not {}'.format(Diagnosis))\n",
    "sns.histplot(data=ResultsFlag1_xgb_log, x=\"Prob\",  binrange=[-8,0.], binwidth=0.25,  stat = 'probability',  color= \"#E0B165\" , label='{}'.format(Diagnosis))\n",
    "plt.legend(loc=2,  title=\"XG Boost\")\n",
    "plt.ylabel(\"Fraction\")\n",
    "\n",
    "y = np.arange(0.,ax.get_ylim()[1],0.01)\n",
    "#print(len(y))\n",
    "x =  np.full(shape = len(y), fill_value = np.log(thresholds[idx]))\n",
    "\n",
    "plt.plot(x,y,label='chance (auc=0.5)',color='k',linestyle='--')\n",
    "plt.ylabel(\"Fraction\")\n",
    "plt.xlabel(\"ln(Score)\")\n",
    "plt.savefig(\"Figures/{}_{}_Score_Plot.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "y_preds2 = np.where(yprobs2<thresholds[idx],0,1)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cmp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_valid, y_preds2, normalize='true')\n",
    "    )\n",
    "#fig, ax = plt.subplots(figsize=(10,10))\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "cmp.plot(cmap=cmap_blended, ax=ax, text_kw={'fontsize':'x-large'})\n",
    "ax.grid(False)\n",
    "# plt.xticks(rotation = 45)\n",
    "\n",
    "\n",
    "# plt.xticks(rotation = 45)\n",
    "plt.savefig(\"Figures/{}_{}_Confusion_Matrix_Plot.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# skew_vars=[]\n",
    "# numeric_features = X_valid.drop(skew_vars, axis=1).select_dtypes(include=['float64', 'int64']).columns #.columns.drop('diagnosis_count')\n",
    "# categorical_features = X_valid.select_dtypes(include=['category', 'object']).columns\n",
    "# # print (numeric_features)\n",
    "# new_cat_cols = best_model['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(categorical_features)\n",
    "# all_cols = np.concatenate([numeric_features, new_cat_cols])\n",
    "# print(all_cols)\n",
    "best_model[1].feature_importances_\n",
    "feat_importances=pd.Series(best_model[1].feature_importances_ , index=all_cols)\n",
    "feat_importances=pd.DataFrame(feat_importances).reset_index()\n",
    "\n",
    "feat_importances.columns=['feature', 'feature_importance']\n",
    "\n",
    "\n",
    "\n",
    "feat_importances.sort_values('feature_importance', ascending=False, inplace=True)\n",
    "# feat_importances=feat_importances.head(15)\n",
    "\n",
    "feat_importances['name'] = None\n",
    "idx = feat_importances.index\n",
    "for i in idx:\n",
    "    # print(i)\n",
    "\n",
    "    val = feat_importances.loc[i].feature\n",
    "    # print(i,val)\n",
    "    try:\n",
    "        tmpValue = plotSettings[val][4]\n",
    "        feat_importances.at[i,'name']= tmpValue[0:tmpValue.rfind(' [')]\n",
    "    except: \n",
    "        for item9 in OtherValues.keys():\n",
    "            if val == item9:\n",
    "                feat_importances.at[i,'name'] = OtherValues[item9]\n",
    "# print(feat_importances)\n",
    "\n",
    "feat_importances15=feat_importances.head(15)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "chart=sns.barplot(x='feature', y='feature_importance', data=feat_importances15, \n",
    "                    order=feat_importances15.sort_values('feature_importance', ascending=False).feature) #color='b')\n",
    "\n",
    "\n",
    "chart.set_xticklabels( list(feat_importances15['name'].values),\n",
    "                      rotation=90, ha=\"center\",\n",
    "                   fontweight='light', fontsize='x-large')\n",
    "# plt.title(\"feature Importance: {a} {b}\".format(a=key,  b=str(\"Stuff\")+': having All Dx'))\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "chart.set(xlabel=None)\n",
    "ax.annotate('{}'.format(tmpString), xy=(0.95, 0.95), xycoords='axes fraction',\n",
    "            fontsize='x-large', ha='right', va='top')\n",
    "plt.savefig(\"Figures/{}_{}_Feature_Importance.png\".format(DiagnosisString,tmpString), dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "feat_importances_XGB = feat_importances.copy()  #.iloc #.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Storage_File = 'Results/{}_{}_FeatureImportances_Pathway_ED.pkl'.format(DataSet,DiagnosisString)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "with open(Data_Storage_File, 'wb') as file:  \n",
    "    pickle.dump((feat_importances_RF,feat_importances_XGB), file)\n",
    "    \n",
    "# from openpyxl import load_workbook\n",
    "Data_Storage_File = 'Results/_{}_{}_FeatureImportances_Pathway_ED.xlsx'.format(DataSet,DiagnosisString)\n",
    "\n",
    "with pd.ExcelWriter(Data_Storage_File, engine='openpyxl') as writer: \n",
    "    feat_importances_RF.to_excel(writer,sheet_name='RandomForest') \n",
    "    feat_importances_XGB.to_excel(writer,sheet_name='XGBoost') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialsXGBoost.trials[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbValues = []\n",
    "varStrings = [\"falsePositive\", \"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\"]\n",
    "scores = {}\n",
    "i=0\n",
    "for i in range(100):\n",
    "    scores = {}\n",
    "    # if i < 2:\n",
    "    scores['max_depth'] = trialsRandomForest.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "    scores['n_estimators'] = trialsRandomForest.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "\n",
    "        # \n",
    "        # 'n_estimators'\n",
    "    for c in varStrings:\n",
    "        # print(c)\n",
    "        key = \"ATTACH::{}::{}\".format(i,c)\n",
    "        scores[c] = trialsRandomForest.attachments[key]\n",
    "        scores[\"i\"] = i\n",
    "    xgbValues.append(scores)\n",
    "# print (scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_XGB_df = pd.DataFrame.from_dict(xgbValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_XGB_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_XGB_df.recall.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails_XGB_df.falsePositive.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 7))\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='n_estimators', y='falsePositive',  alpha=.75, palette=\"muted\", label='False Positive Rate')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='n_estimators', y='accuracy',  alpha=.75, palette=\"muted\", label='Accuracy')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='n_estimators', y='recall',  alpha=.75, palette=\"muted\", label='Recall')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='n_estimators', y='precision',  alpha=.75, palette=\"muted\", label='Precision')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='n_estimators', y='f1',  alpha=.75, palette=\"muted\", label='F1')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 7))\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='max_depth', y='falsePositive',  alpha=.75, palette=\"muted\", label='False Positive Rate')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='max_depth', y='accuracy',  alpha=.75, palette=\"muted\", label='Accuracy')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='max_depth', y='recall',  alpha=.75, palette=\"muted\", label='Recall')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='max_depth', y='precision',  alpha=.75, palette=\"muted\", label='Precision')\n",
    "g = sns.scatterplot(data=trails_XGB_df, x='max_depth', y='f1',  alpha=.75, palette=\"muted\", label='F1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceihml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
