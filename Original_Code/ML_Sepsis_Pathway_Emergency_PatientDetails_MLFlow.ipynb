{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Sepsis Pathway  with MLFlow\n",
    "\n",
    "Setup Libraries and plotting defaults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "c:\\Users\\ibertr02\\venvs\\ceihml\\Lib\\site-packages\\snowflake\\connector\\options.py:103: UserWarning: You have an incompatible version of 'pyarrow' installed (15.0.2), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n",
      "Failed to import ArrowResult. No Apache Arrow result set format can be used. ImportError: DLL load failed while importing arrow_iterator: The specified procedure could not be found.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import statsmodels.formula.api as smf\n",
    "#from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from pandasql import sqldf\n",
    "import sqlalchemy\n",
    "import pyodbc\n",
    "\n",
    "import dfply as dfp\n",
    "from dfply import *\n",
    "\n",
    "import datetime\n",
    "from datetime import *\n",
    "\n",
    "import pyodbc\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics         import balanced_accuracy_score, precision_score, classification_report\n",
    "from sklearn.metrics         import recall_score, f1_score, make_scorer, cohen_kappa_score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import forestci as fci\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer, PowerTransformer\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, roc_auc_score, accuracy_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#from statsmodels.tools.tools import add_constant\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "n_est=55\n",
    "\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import Utilities\n",
    "import importlib\n",
    "importlib.reload(Utilities)\n",
    "\n",
    "import MLUtilities\n",
    "importlib.reload(MLUtilities)\n",
    "\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "plt.style.use('./CEIH.mplstyle')\n",
    "color_dict = {0: to_rgba('#32C0D2', 1),\n",
    "                1: to_rgba(\"#E0B165\", 1),}\n",
    "\n",
    "cmap_blended = sns.blend_palette([\"#ADE6ED\",\"#70D3E0\",\"#32C0D2\",\"#289AA8\",\"#307078\"], as_cmap=True)\n",
    "\n",
    "\n",
    "import math\n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "    \n",
    "OtherValues = {'TriageCategory_2':'Triage Category 2', 'SoBFlag': 'Shortness of Breath', 'TriageCategory_4':'Triage Category 4',\n",
    "               'TriageCategory_1':'Triage Category 1', 'TriageCategory_5':'Triage Category 5', 'TriageCategory_3':'Triage Category 3',\n",
    "             'FirstGCSScoreAdult':'Glasgow Coma Scale',\n",
    "               'FirstUrinalysisBlood': 'Urinalysis Blood', 'IndigenousStatusDescription_Not Aboriginal-TSI':  'Non Indiginous',\n",
    "               'IndigenousStatusDescription_Not Stated':  'Indiginous Status not stated', 'FirstUrinalysisLeukocytes':'Urinalysis Leukocytes',\n",
    "               'FirstPulseRateBPM':'Pulse Rate', 'FirstRespiration':'Respiration Rate', 'FirstSpO2':'O2 Saturation (%)',  'Gender_Male':'Sex - Male',\n",
    "               'FirstLevelofConsciousness':'Level of Consciousness', 'IndigenousStatusDescription_Aboriginal and TSI':'Aboriginal and TSI',\n",
    "               'IndigenousStatusDescription_TSI':'TSI','Gender_Indeterminate':'Sex - Indeterminate', 'Gender_Unknown':'Sex - Unknown',\n",
    "               'FirstO2Flow':'O2 Flow '\n",
    "               }\n",
    "\n",
    "\n",
    "plotSettings = {\n",
    "        #  ( bins, xmin, xmax, log/linear)\n",
    "        'AGEONADMISSION':(50,20,110,'linear','Age (y)', False, 0,0),\n",
    "        \n",
    "        \n",
    "        'FirstBloodGlucose':(50,0,100,'log','Blood Glucose [mmol/L]', False,0, 0),\n",
    "        'FirstTemperatureDegreesC':(50,30,45,'log', r\"Temperature [$^\\circ$C]\", True,35.5,38.1),\n",
    "                'FirstWeightKg':(50,50,150,'log','Weight [kg]', False, 0,0),\n",
    "\n",
    "        \n",
    "        'FirstPainAssessment': (11,-0.5,10.5,'log','Pain Assessment', False, 0,0),\n",
    "        'FirstBPSystolic': (50,50,250,'log', 'BP Systolic [mm Hg]',True, 100,170 ),\n",
    "        'FirstBPDiastolic': (50,0,200,'log', 'BP Diastolic [mm Hg]', False,0,0),\n",
    "        'FirstEstimatedGlomerularFiltrationRate': (50,0,100,'log',r\"Estimated Glomerular Filtration Rate [mL/min/1.73m$^{2}$]\", True, 60, 100),\n",
    "        'FirstCreatinine': (50,0,800,'log',r\"Creatinine - Serum [$\\mu$mol/L]\", True, 45, 110),\n",
    "        'FirstAlbumin': (60,0,60,'log','Albumin  Level [g/L]', True, 30, 48),\n",
    "        'FirstTotalBilirubin': (60,0,100,'log',r\"Total Bilirubin Level [$\\mu$mol/L]\", True, 2, 24 ),\n",
    "        'FirstAlkalinePhosphatase': (60,0,800,'log','Alkaline Phosphatase Level [U/L]',True, 30,110),\n",
    "        'FirstAlanineAminotransferase': (60,0,700,'log','Alanine Aminotransferase Level [U/L]', True,0,55),\n",
    "        'FirstAspartateAminotransferase': (60,0,700,'log','Aspartate Aminotransferase Level [U/L]', True, 0,45),\n",
    "        'FirstGammaGlutamylTransferase': (60,0,700,'log','Gamma Glutamyl Transferase Level [U/L]', True, 0, 60),\n",
    "        'FirstLactateDehydrogenase': (60,0,1200,'log','Lactate Dehydrogenase [U/L]', True, 120, 250),\n",
    "        'FirstHaemoglobin': (50,10, 220,'log','Haemoglobin [g/L]', True, 115, 175),\n",
    "        'FirstWhiteCellCount': (50,0, 50,'log',r\"White Cell Count [$\\times 10^{9}$/L]\",True, 4,11),\n",
    "        'FirstPlateletCount': (50,0, 1000,'log',r\"Platelet Count [$\\times 10^{9}$/L]\",True,150,500),\n",
    "        'FirstNeutrophils': (50,0, 50,'log',r\"Absolute Neutrophil Count [$\\times 10^{9}$/L]\",True,1.80,7.50),\n",
    "        'FirstDDimer': (40,0, 20,'log',r\"D-Dimer [mg/L]\",True,0,0.79),\n",
    "        'FirstCreactiveprotein': (50,0, 600,'log',r\"C-Reactive Protein [mg/L]\",True, 0,8),\n",
    "        'FirstTroponinT': (50,0, 600,'log',r\"Troponin T Level [mg/L]\",True,0,16),\n",
    "        'FirstNTproBNP': (50,0, 40000,'log',r\"NT-pro Brain Natriuretic Peptide [mg/L]\",True,0,124),\n",
    "        \n",
    "        'FirstAnionGapVenous': (50,0, 50,'log',r\"Anion Gap Venous [mmol/L]\", True, 7, 17),\n",
    "        'FirstAnionGapArterial': (50,0, 50,'log',r\"Anion Gap Arterial [mmol/L]\",  True, 7, 17),\n",
    "        'FirstBaseExcessVenous': (50,-30, 30,'log',r\"Base Excess Venous [mmol/L]\", True, -3, 3),\n",
    "        'FirstBaseExcessArterial': (50,-30, 30,'log',r\"Base Excess Arterial [mmol/L]\", True, -3, 3),\n",
    "        'FirstBilirubinVenous': (60,0, 60,'log',r\"Bilirubin Venous [$\\mu$mol/L]\", True, 2,24),\n",
    "        'FirstBilirubinArterial': (60,0, 60,'log',r\"Bilirubin Arterial [$\\mu$mol/L]\", True, 2,24),\n",
    "        'FirstCarboxyhaemoglobinVenous': (50,0, 20,'log',r\"Carboxyhaemoglobin Venous [%]\", True, 0.3, 1.8),\n",
    "        'FirstCarboxyhaemoglobinArterial': (50,0, 20,'log',r\"Carboxyhaemoglobin Arterial [%]\", True, 0.3, 1.8),\n",
    "        'FirstChlorideDirectVenous': (50,50, 150,'log',r\"Chloride Direct Venous [mmol/L]\",False, 100,109),\n",
    "        'FirstChlorideDirectArterial': (50,50, 150,'log',r\"Chloride Direct Arterial [mmol/L]\", True, 100,109),\n",
    "        'FirstCreatinineVenous':(50,0,500,'log',r\"Creatinine Venous [$\\mu$mol/L]\", True, 50, 120),\n",
    "        'FirstCreatinineArterial':(50,0,500,'log',r\"Creatinine Arterial [$\\mu$mol/L]\", True, 50,120),\n",
    "        'FirstGlucoseVenous':(50,0,30,'log',r\"Glucose  Venous [mmol/L]\", False,0,0),\n",
    "        'FirstGlucoseArterial':(50,0,30,'log',r\"Glucose  Arterial [mmol/L]\", True,2.6,5.6),\n",
    "        'FirstIonised Calcium Venous':(50,0,2,'log',r\"Ionised Calcium Venous [mmol/L]\", True, 1.1, 1.3),\n",
    "        'FirstIonised Calcium Arterial':(50,0,2,'log',r\"Ionised Calcium Arterial [mmol/L]\", True, 1.1, 1.3),\n",
    "        'FirstLactateVenous':(50,0,30,'log',r\"Lactate Venous [mmol/L]\", True, 0.2, 2.0),\n",
    "        'FirstLactateArterial':(50,0,30,'log',r\"Lactate Arterial [mmol/L]\", True, 0.2, 2.0),\n",
    "        'FirstMethaemoglobinVenous': (20,0, 3,'log',r\"Methaemoglobin Venous [%]\", True, 0.4, 1.2),\n",
    "        'FirstMethaemoglobinArterial': (20,0, 3,'log',r\"Methaemoglobin Arterial [%]\", True, 0.2,0.6),\n",
    "        'FirstOxygenSaturationVenous': (50,0, 100,'log',r\"Oxygen Saturation Venous [%]\", False, 0,0),\n",
    "        'FirstOxygenSaturationArterial': (50,0, 100,'log',r\"Oxygen Saturation Arterial [%]\", True,95, 99),\n",
    "        'FirstOxyhaemoglobinVenous': (50,0, 100,'log',r\"Oxyhaemoglobin Venous [%]\", False, 0,0),\n",
    "        'FirstOxyhaemoglobinArterial': (50,0, 100,'log',r\"Oxyhaemoglobin Arterial [%]\", False, 0,0),\n",
    "        'FirstReducedHaemoglobinVenous': (50,0, 100,'log',r\"Reduced Haemoglobin Venous [%]\", False, 0,0),\n",
    "        'FirstReducedHaemoglobinArterial': (50,0, 100,'log',r\"Reduced Haemoglobin Arterial [%]\", False, 0,0),\n",
    "        'FirstTotalHaemoglobinVenous': (50,10, 220,'log','Total Haemoglobin Venous [g/L]', True, 115,180),\n",
    "        'FirstTotalHaemoglobinArterial': (50,10, 220,'log','Total Haemoglobin Arterial [g/L]', True, 115,180), \n",
    "        'FirstpCO2Venous': (50,0,150,'log', 'pCO2 Venous [mm Hg]', True,41,51),\n",
    "        'FirstpCO2Arterial': (50,0,150,'log', 'pCO2 Arterial [mm Hg]', True, 35, 45 ),\n",
    "        'FirstpO2Venous': (50,0,200,'log', 'pO2 Venous [mm Hg]', True, 25,40),\n",
    "        'FirstpO2Arterial': (50,0,200,'log', 'pO2 Arterial [mm Hg]', True,67, 108),\n",
    "        'FirstpHVenous': (50,6.8,7.8,'log', 'pH Venous', True, 7.32,7.42),\n",
    "        'FirstpHArterial': (50,6.8,7.8,'log', 'pH Arterial', True, 7.36, 7.44),\n",
    "        'FirstPotassiumDirectVenous':(50,0,10,'log',r\"Potassium Direct Venous [mmol/L]\", False, 0,0),\n",
    "        'FirstPotassiumDirectArterial':(50,0,10,'log',r\"Potassium Direct Arterial [mmol/L]\", True, 3.1, 4.2),\n",
    "        'FirstSodiumDirectVenous':(50,100,180,'log',r\"Sodium Direct Venous [mmol/L]\", False, 0,0),\n",
    "        'FirstSodiumDirectArterial':(50,100,180,'log',r\"Sodium Direct Arterial [mmol/L]\", True, 137, 145),}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepsis SepsisFlag\n"
     ]
    }
   ],
   "source": [
    "# Sepsis HeartFailure PE Pneumonia COPD UTI\n",
    "# SepsisPneumonia\n",
    "Diagnosis =   \"Sepsis\"\n",
    "# Diagnosis = 'SepsisPneumonia'\n",
    "# Diagnosis = 'Admission'\n",
    "# Diagnosis = 'GenMed'\n",
    "\n",
    "DiagnosisString=Diagnosis+'Flag'\n",
    "\n",
    "# DataSet1 All observations \n",
    "# DataSet2 Not including Oxygen Flow \n",
    "# Dataset3  Dataset2 plus age and gender\n",
    "#  Dataset4 3 plus restriction on TC to 3 4 and 5 \n",
    "#  Dataset 5 with LoS > 6 hours. \n",
    "# Datset30 includes indiginous\n",
    "#  60 remove < 18, include gender and not age... \n",
    "\n",
    "\n",
    "DataSet = 'DataSet3'\n",
    "\n",
    "# MLModel = 'randomforest'\n",
    "\n",
    "print(Diagnosis,DiagnosisString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date =  '2023-01-01'  #dates[Facility][0]\n",
    "end_date   =  '2024-01-01' #dates[Facility][1]\n",
    "\n",
    "select_start_date = '2023-01-01'\n",
    "\n",
    "DataReasons = \"Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_2023-01-01_2024-01-01_Training_Stage_01.pkl\n"
     ]
    }
   ],
   "source": [
    "Data_Storage_File = 'DataFiles\\Emergency_IPInfo_Complete_Numeric_Numeric_{}_{}_{}_Stage_01.pkl'.format(start_date,end_date,DataReasons)\n",
    "print(Data_Storage_File)\n",
    "\n",
    "\n",
    "with open(Data_Storage_File, 'rb') as file:\n",
    "    Emergency_IPInfo_Complete_Numeric = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emergency_IPInfo_Complete_Numeric = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION>17].copy()\n",
    "importlib.reload(MLUtilities)\n",
    "Emergency_IPInfo_Complete_Numeric = MLUtilities.setNumeric(Emergency_IPInfo_Complete_Numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(0,17),'age_range']='0-17'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(18,33),'age_range']='18-33'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(34,48),'age_range']='34-48'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(49,64),'age_range']='49-64'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(65,78),'age_range']='65-78'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(79,98),'age_range']='79-98'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(98,120),'age_range']='98+'\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.AGEONADMISSION.between(121,200),'age_range']='Unknown'\n",
    "\n",
    "\n",
    "Emergency_IPInfo_Complete_Numeric['IndiginousFlag'] = 0  # np.where((Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isna()|Emergency_IPInfo_Complete_Numeric.IndiginousStatus=='Not Aboriginal-TSI'),0,1)\n",
    "Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.IndiginousStatus.isin(['Aboriginal','Aboriginal and TSI', 'TSI']),'IndiginousFlag'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['65-78', '79-98', '34-48', '49-64', '98+', '18-33', 'Unknown'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emergency_IPInfo_Complete_Numeric.age_range.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Machine Learning Information \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis being investigated = SepsisFlag\n",
      "Total Number of Cases = 277021\n",
      "Number of SepsisFlag Cases  2733\n"
     ]
    }
   ],
   "source": [
    "GenMedList = ['LMH-LGMED','LMH-LAMU',\n",
    "              \"MPH-MGMED\", \n",
    "              \"FMC-GENMED\",\n",
    "              \"NHS-GENMED\",\n",
    "              \"RAH-GENMED\",\n",
    "              \"QEH-GENMED\", 'QEH-GM-AMU'\n",
    "              ]\n",
    "\n",
    "\n",
    "# DiagnosisString='SepsisFlag'\n",
    "\n",
    "if Diagnosis == \"SepsisPneumonia\":\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric.SepsisFlag==1)|(Emergency_IPInfo_Complete_Numeric.PneumoniaFlag==1), DiagnosisString] = 1\n",
    "\n",
    "if Diagnosis == 'Admission':\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>24), DiagnosisString] = 1\n",
    "    \n",
    "    if DataSet == 'DataSet5':\n",
    "        Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "        Emergency_IPInfo_Complete_Numeric.loc[ (Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>6), DiagnosisString] = 1\n",
    "\n",
    "\n",
    "if Diagnosis == 'GenMed':\n",
    "    Emergency_IPInfo_Complete_Numeric[DiagnosisString] = 0\n",
    "    for g in GenMedList:\n",
    "        Emergency_IPInfo_Complete_Numeric.loc[(Emergency_IPInfo_Complete_Numeric.GROUPCODE.str.contains(g))  & (Emergency_IPInfo_Complete_Numeric['InitialIPLoS']>6), DiagnosisString] = 1\n",
    "   \n",
    "\n",
    "\n",
    "print(\"Diagnosis being investigated = {}\".format(DiagnosisString))\n",
    "print(\"Total Number of Cases = {}\".format(len(Emergency_IPInfo_Complete_Numeric.index)))\n",
    "print(\"Number of {} Cases \".format(DiagnosisString),len(Emergency_IPInfo_Complete_Numeric[Emergency_IPInfo_Complete_Numeric[DiagnosisString]==1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DataSet == 'DataSet4':\n",
    "    df = Emergency_IPInfo_Complete_Numeric.loc[Emergency_IPInfo_Complete_Numeric.TRIAGE_CATEGORY>2].copy()\n",
    "else:\n",
    "    df = Emergency_IPInfo_Complete_Numeric.copy()\n",
    "\n",
    "df.name='{} diagnosis detected from full Diagnosis list, updated'.format(Diagnosis)\n",
    "importlib.reload(MLUtilities)\n",
    "df = MLUtilities.setDefaults(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnalysisVariable =['FirstBPSystolic', 'FirstLevelofConsciousness',\n",
    "       'FirstPulseRateBPM', 'FirstRespiration', 'FirstSpO2',\n",
    "       'FirstTemperatureDegreesC', \n",
    "       DiagnosisString]\n",
    "\n",
    "if DataSet == 'DataSet1':\n",
    "       AnalysisVariable.append('FirstO2Flow')\n",
    "elif DataSet == 'DataSet3':\n",
    "       AnalysisVariable.append('GENDERCODE')\n",
    "       AnalysisVariable.append('AGEONADMISSION')\n",
    "elif (DataSet == 'DataSet4') or (DataSet == 'DataSet5'):\n",
    "       AnalysisVariable.append('GENDERCODE')\n",
    "       AnalysisVariable.append('AGEONADMISSION')\n",
    "elif DataSet == 'DataSet30':\n",
    "       AnalysisVariable.append('GENDERCODE')\n",
    "       AnalysisVariable.append('AGEONADMISSION')\n",
    "       AnalysisVariable.append('IndiginousFlag')\n",
    "# elif DataSet == 'DataSet40':\n",
    "#        AnalysisVariable.append('GENDERCODE')\n",
    "#        AnalysisVariable.append('age_range')\n",
    "       # AnalysisVariable.append('IndiginousFlag')\n",
    "# elif DataSet == 'DataSet60':\n",
    "#        AnalysisVariable.append('GENDERCODE')\n",
    "#        # AnalysisVariable.append('age_range')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df[AnalysisVariable].copy()\n",
    "# df_temp[DiagnosisString] = df_temp[DiagnosisString].astype('category')\n",
    "# df_temp['TriageCategory'] = df_temp['TriageCategory'].astype('category')\n",
    "# df_temp['Gender'] = df_temp['Gender'].astype('category')\n",
    "# df_temp['IndigenousStatusDescription'] = df_temp['IndigenousStatusDescription'].astype('category')                           \n",
    "# df_temp['SoBFlag'] = df_temp['SoBFlag'].astype('category')\n",
    "# df_temp.dropna(inplace=True)\n",
    "\n",
    "\n",
    "if DataSet == 'DataSet3':\n",
    "    df_temp['GENDERCODE'] = df_temp['GENDERCODE'].astype('category')\n",
    "\n",
    "if DataSet == 'DataSet30':\n",
    "    df_temp['GENDERCODE'] = df_temp['GENDERCODE'].astype('category')\n",
    "    df_temp['IndiginousFlag'] = df_temp['IndiginousFlag'].astype('category')\n",
    "\n",
    "if DataSet == 'DataSet40':\n",
    "    df_temp['GENDERCODE'] = df_temp['GENDERCODE'].astype('category')\n",
    "    # df_temp['IndiginousFlag'] = df_temp['IndiginousFlag'].astype('category')\n",
    "    df_temp['age_range'] = df_temp['age_range'].astype('category')\n",
    "\n",
    "# if DataSet == 'DataSet60':\n",
    "#     df_temp['GENDERCODE'] = df_temp['GENDERCODE'].astype('category')\n",
    "#     # df_temp['IndiginousFlag'] = df_temp['IndiginousFlag'].astype('category')\n",
    "#     # df_temp['age_range'] = df_temp['age_range'].astype('category')\n",
    "\n",
    "\n",
    "# SMOTE does not work if NAN is allowed so int instead of Int \n",
    "    \n",
    "numeric_features = df_temp.select_dtypes(\n",
    "        include=[ 'int64', 'Int64', 'int32']).columns\n",
    "\n",
    "for key in numeric_features:\n",
    "    df_temp[key] = df_temp[key].astype('int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_temp[[DiagnosisString]]\n",
    "X = df_temp[AnalysisVariable].drop(DiagnosisString, axis=1).copy()\n",
    "x_vars = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables included in model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['GENDERCODE'], dtype='object'),\n",
       " Index(['FirstBPSystolic', 'FirstLevelofConsciousness', 'FirstPulseRateBPM',\n",
       "        'FirstRespiration', 'FirstSpO2', 'FirstTemperatureDegreesC',\n",
       "        'AGEONADMISSION'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skew_vars = []\n",
    "\n",
    "numeric_features = X.drop(skew_vars, axis=1).select_dtypes(\n",
    "        include=['float64', 'int64']).columns\n",
    "\n",
    "categorical_features = X.select_dtypes(\n",
    "        include=['category', 'object']).columns\n",
    "\n",
    "categorical_features,numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENDERCODE ['Female', 'Male', 'Indeterminate', 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', MinMaxScaler()),  # StandardScaler #MinMaxScaler\n",
    "        #('skew', FunctionTransformer(log_transform))\n",
    "    ])\n",
    "\n",
    "category_values = []\n",
    "for i in categorical_features:\n",
    "    print(i,pd.unique(df_temp[i]).tolist())\n",
    "    category_values.append(pd.unique(df_temp[i]).tolist())\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore',categories=category_values   ))])  # OrdinalEncoder() #OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', numeric_transformer, numeric_features),\n",
    "            ('categorical', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "def pip_f(reg):\n",
    "    pip = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', reg)\n",
    "    ])\n",
    "    return(pip)\n",
    "\n",
    "functions = {\n",
    "        # 'decisiontree': DecisionTreeClassifier(class_weight='balanced', random_state=n_est),   #######class_weight='balanced' check this\n",
    "        'randomforest': RandomForestClassifier(class_weight='balanced', random_state=n_est),\n",
    "        # 'knn': KNeighborsClassifier(),\n",
    "        # 'xgboost':xgb.XGBClassifier (class_weight='balanced', random_state=n_est)\n",
    "        'xgboost':xgb.XGBClassifier ( random_state=n_est) # class_weight='balanced' not in xgboost??\n",
    "    }\n",
    "\n",
    "key = 'randomforest'\n",
    "best_performance = {}\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categorical_features)>0:\n",
    "    smote = SMOTENC(random_state=42, categorical_features=[X_train.columns.get_loc(c) for c in categorical_features])\n",
    "    X_train, y_train= smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepsis diagnosis detected from full Diagnosis list, updated\n"
     ]
    }
   ],
   "source": [
    "df.name='Sepsis diagnosis detected from full Diagnosis list, updated'\n",
    "\n",
    "print(df.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Iain Mucking Around\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.xgboost.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train.index),len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "# dtest = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "n_est = 52\n",
    "\n",
    "with mlflow.start_run():\n",
    "    params = {\n",
    "        'random_state': n_est, \n",
    "        'max_depth': 20, \n",
    "        # 'n_estimators': 50,\n",
    "        'learning_rate': 0.3,  # New \n",
    "        'subsample':1.,     # New\n",
    "        # \"num_class\": 3,\n",
    "        # \"eval_metric\": \"mlogloss\",\n",
    "    }\n",
    "    preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numeric', numeric_transformer, numeric_features),\n",
    "                ('categorical', categorical_transformer, categorical_features)\n",
    "            ])\n",
    "\n",
    "    classifier = xgb.XGBClassifier(**params)\n",
    "\n",
    "    model = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", classifier)\n",
    "            ])\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    # # y_proba = model.predict(dtest)\n",
    "    # y_pred = y_proba.argmax()\n",
    "    # loss = log_loss(y_valid, y_proba)\n",
    "    # acc = accuracy_score(y_valid, y_pred)\n",
    "\n",
    "    predictions_valid = model.predict_proba(X_valid)\n",
    "    ypreds = np.delete(predictions_valid,[0],1)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold =   np.interp(0.85,tpr,thresholds)    #thresholds[idx]\n",
    "    false_positive =  np.interp(0.85,tpr,fpr)      # fpr[idx]\n",
    "    # redo predictions with new threshold \n",
    "    y_select_2 = np.where(ypreds<threshold,0,1)\n",
    "    auc_score = roc_auc_score(y_valid, ypreds, multi_class=\"ovr\", average=\"weighted\")\n",
    "    auc_score2 = roc_auc_score(y_valid, ypreds)\n",
    "    accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "    balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "    recall  =recall_score(y_valid, y_select_2)\n",
    "    precision = precision_score(y_valid, y_select_2)\n",
    "    f1 = f1_score(y_valid, y_select_2)\n",
    "\n",
    "    val,idx = find_nearest(tpr,0.85)\n",
    "    threshold2 = thresholds[idx]\n",
    "    false_positive2 = fpr[idx]\n",
    "\n",
    "    mlflow.log_metrics({'loss': false_positive, \"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score,\n",
    "              \"falsePositive2\":false_positive2,\n",
    "              \"threshold\":threshold,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 10:22:42 INFO mlflow.tracking.fluent: Experiment with name 'Iain Hyperopt Test' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///e:/105GenMed-ML-OLd/GenMed105-DxPrediction/SnowFlakeVersion/mlruns/209495169642519356', creation_time=1730850762588, experiment_id='209495169642519356', last_update_time=1730850762588, lifecycle_stage='active', name='Iain Hyperopt Test', tags={}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Iain Hyperopt Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "space4xgbsepsis = {\n",
    "    # 'random_state': n_est, \n",
    "    'max_depth': hp.choice('max_depth', np.arange(1,30, 1, dtype=int)), \n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(1, 200, 1, dtype=int)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),  # New \n",
    "    'subsample':hp.uniform('subsample', 0.5, 1.),     # New\n",
    "    'seed':hp.choice('seed',[0,7,42])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective (params):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        \n",
    "        \n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        classifier = xgb.XGBClassifier(**params)\n",
    "\n",
    "        model = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", classifier)\n",
    "        ])\n",
    "        \n",
    "        model.fit(X_train, np.ravel(y_train,order=\"c\"))\n",
    "        predictions_valid = model.predict_proba(X_valid)\n",
    "        ypreds = np.delete(predictions_valid,[0],1)\n",
    "    \n",
    "        fpr, tpr, thresholds = roc_curve(y_valid, ypreds)\n",
    "        val,idx = find_nearest(tpr,0.85)\n",
    "        threshold =   np.interp(0.85,tpr,thresholds)    #thresholds[idx]\n",
    "        false_positive =  np.interp(0.85,tpr,fpr)      # fpr[idx]\n",
    "        # redo predictions with new threshold \n",
    "        y_select_2 = np.where(ypreds<threshold,0,1)\n",
    "        auc_score = roc_auc_score(y_valid, ypreds, multi_class=\"ovr\", average=\"weighted\")\n",
    "        auc_score2 = roc_auc_score(y_valid, ypreds)\n",
    "        accuracy  =accuracy_score(y_valid, y_select_2)\n",
    "        balanced_accuracy = balanced_accuracy_score (y_valid, y_select_2)\n",
    "        recall  =recall_score(y_valid, y_select_2)\n",
    "        precision = precision_score(y_valid, y_select_2)\n",
    "        f1 = f1_score(y_valid, y_select_2)\n",
    "    \n",
    "        scores = {\"falsePositive\":false_positive,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"precision\":precision,\n",
    "              \"recall\":recall,\n",
    "              \"precision\":precision,\n",
    "              \"f1\":f1,\n",
    "              \"auc\":auc_score,\n",
    "              \"auc2\":auc_score2,\n",
    "            #   \"falsePositive2\":false_positive2,\n",
    "              \"threshold\":threshold,\n",
    "             }\n",
    "    \n",
    "        mlflow.log_metrics({'loss': false_positive, \"falsePositive\":false_positive,\n",
    "            \"accuracy\":accuracy,\n",
    "            \"precision\":precision,\n",
    "            \"recall\":recall,\n",
    "            \"precision\":precision,\n",
    "            \"f1\":f1,\n",
    "            \"auc\":auc_score,\n",
    "            # \"falsePositive2\":false_positive2,\n",
    "            \"threshold\":threshold,})\n",
    "    \n",
    "    return {'status': STATUS_OK, 'loss': false_positive, 'model': model, 'attachments':scores} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:12:47<00:00,  7.97s/trial, best loss: 0.20494640708738923] \n"
     ]
    }
   ],
   "source": [
    "n_trials = 1000\n",
    "\n",
    "trialsXGBoost = Trials()\n",
    "\n",
    "best_params_XGB = fmin(fn = objective,\n",
    "                    space = space4xgbsepsis,\n",
    "                    algo = tpe.suggest,\n",
    "                    max_evals = n_trials, \n",
    "                    trials = trialsXGBoost\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.058495033316467944,\n",
       " 'max_depth': 0,\n",
       " 'n_estimators': 69,\n",
       " 'seed': 1,\n",
       " 'subsample': 0.7575856608007053}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = np.argmin([r['loss'] for r in trialsXGBoost.results])\n",
    "scoreXGBoost = [t['result']['loss'] for t in trialsXGBoost.trials]\n",
    "best_model_XGBoost=trialsXGBoost.results[np.argmin([r['loss'] for r in trialsXGBoost.results])]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'A xgBoost model on real data'\n",
    "tags = {'version': 'v0.1', 'type': 'demo'}\n",
    "experiment_name = 'Sklearn Pipeline Tutorial'\n",
    "registered_model_name = 'xgb - dataset3'\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'439434785447189246'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.create_experiment(name=experiment_name,\n",
    "                         tags=tags,\n",
    "                         artifact_location=Path.cwd().joinpath('mlruns').as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///e:/105GenMed-ML-OLd/GenMed105-DxPrediction/SnowFlakeVersion/mlruns', creation_time=1730864940755, experiment_id='439434785447189246', last_update_time=1730864940755, lifecycle_stage='active', name='Sklearn Pipeline Tutorial', tags={'type': 'demo', 'version': 'v0.1'}>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'falsePositive': 0.20494640708738923,\n",
       " 'threshold': 0.4606784999370575,\n",
       " 'accuracy': 0.7955960653370634,\n",
       " 'precision': 0.039637792584999144,\n",
       " 'recall': 0.8482632541133455,\n",
       " 'f1': 0.07573655431322941,\n",
       " 'auc': 0.89173515494183}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {}\n",
    "i = pointer\n",
    "varStrings = [\"falsePositive\",  \"threshold\",\"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\"]\n",
    "for c in varStrings:\n",
    "    # print(c)\n",
    "    key = \"ATTACH::{}::{}\".format(i,c)\n",
    "    scores[c] = trialsXGBoost.attachments[key]\n",
    "    # scores[\"i\"] = i\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_XGBoost.get_params()\n",
    "signature  = mlflow.models.infer_signature(best_model_XGBoost.predict(X_train))\n",
    "# mlflow.data.from_pandas(df_temp,targets=DiagnosisString).to_dict()\n",
    "best_params = best_params_XGB\n",
    "best_metrics_dict = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ibertr02\\venvs\\ceihml\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/08 12:44:55 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: MlflowException(\"Failed to enforce schema of data '   FirstBPSystolic  FirstLevelofConsciousness  FirstPulseRateBPM  \\\\\\n0              122                        0.0                102   \\n1              122                        0.0                 80   \\n2              143                        0.0                 86   \\n3              122                        0.0                 75   \\n4              131                        0.0                 97   \\n\\n   FirstRespiration  FirstSpO2  FirstTemperatureDegreesC GENDERCODE  \\\\\\n0                16         98                      36.5     Female   \\n1                16        100                      36.6     Female   \\n2                20         96                      36.0     Female   \\n3                18         98                      36.9       Male   \\n4                18         98                      36.7     Female   \\n\\n   AGEONADMISSION  \\n0              43  \\n1              60  \\n2              77  \\n3              73  \\n4              50  ' with schema '['FirstBPSystolic': long (required), 'FirstLevelofConsciousness': double (required), 'FirstPulseRateBPM': long (required), 'FirstRespiration': long (required), 'FirstSpO2': long (required), 'FirstTemperatureDegreesC': double (required), 'GENDERCODE': string (required), 'AGEONADMISSION': long (required)]'. Error: Incompatible input types for column GENDERCODE. Can not safely convert category to <U0.\"). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`. To disable automatic signature inference, set `signature` to `False` in your `log_model` or `save_model` call.\n",
      "Registered model 'xgb - dataset3' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'xgb - dataset3'.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 437.54it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x20aaa47f050>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with mlflow.start_run(run_name='Parent Run', description=description) as run:\n",
    "#     run_id = run.info.run_id\n",
    "\n",
    "mlflow.log_params(best_params)\n",
    "mlflow.log_metrics(best_metrics_dict)\n",
    "mlflow.sklearn.log_model(best_model_XGBoost, 'best_model',\n",
    "                            # signature=signature,\n",
    "                            input_example=X_train.head(5),\n",
    "                            registered_model_name=registered_model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibertr02\\AppData\\Local\\Temp\\ipykernel_42560\\283172245.py:3: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(name=registered_model_name,version=3,stage=stage)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1731032102236, current_stage='Staging', description=None, last_updated_timestamp=1731038897712, name='xgb - dataset3', run_id='fc511fc624a8423eb45c77ad0a37b9cd', run_link=None, source='file:///e:/105GenMed-ML-OLd/GenMed105-DxPrediction/SnowFlakeVersion/mlruns/fc511fc624a8423eb45c77ad0a37b9cd/artifacts/best_model', status='READY', status_message=None, tags={}, user_id=None, version=3>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage = 'staging'\n",
    "client = mlflow.MlflowClient()\n",
    "client.transition_model_version_stage(name=registered_model_name,version=3,stage=stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ibertr02\\venvs\\ceihml\\Lib\\site-packages\\mlflow\\store\\artifact\\utils\\models.py:31: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest = client.get_latest_versions(name, None if stage is None else [stage])\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_uri=f'models:/{registered_model_name}/{stage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_valid.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbValues = []\n",
    "varStrings = [\"falsePositive\",  \"threshold\",\"accuracy\", \"precision\", \"recall\",\"precision\",\"f1\", \"auc\",\"auc2\"]\n",
    "scores = {}\n",
    "i=0\n",
    "for i in range(n_trials):\n",
    "    scores = {}\n",
    "    # if i < 2:\n",
    "    scores['max_depth'] = trialsXGBoost.trials[i]['misc']['vals']['max_depth'][0]+1\n",
    "    scores['n_estimators'] = trialsXGBoost.trials[i]['misc']['vals']['n_estimators'][0]+1\n",
    "    scores['learning_rate'] = trialsXGBoost.trials[i]['misc']['vals']['learning_rate'][0]+1\n",
    "    scores['subsample'] = trialsXGBoost.trials[i]['misc']['vals']['subsample'][0]+1\n",
    "    scores['seed'] = trialsXGBoost.trials[i]['misc']['vals']['seed'][0]\n",
    "\n",
    "    \n",
    "\n",
    "        # \n",
    "        # 'n_estimators'\n",
    "    for c in varStrings:\n",
    "        # print(c)\n",
    "        key = \"ATTACH::{}::{}\".format(i,c)\n",
    "        scores[c] = trialsXGBoost.attachments[key]\n",
    "        scores[\"i\"] = i\n",
    "    xgbValues.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'attach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrialsXGBoost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmisc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'attach'"
     ]
    }
   ],
   "source": [
    "trialsXGBoost.trials[10]['misc']['attach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 10,\n",
       " 'spec': None,\n",
       " 'result': {'status': 'ok',\n",
       "  'loss': 0.3338984286703854,\n",
       "  'model': Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('numeric',\n",
       "                                                    Pipeline(steps=[('scaler',\n",
       "                                                                     MinMaxScaler())]),\n",
       "                                                    Index(['FirstBPSystolic', 'FirstLevelofConsciousness', 'FirstPulseRateBPM',\n",
       "         'FirstRespiration', 'FirstSpO2', 'FirstTemperatureDegreesC',\n",
       "         'AGEONADMISSION'],\n",
       "        dtype='object')),\n",
       "                                                   ('categorical',\n",
       "                                                    Pipeline(steps=[('encoder',\n",
       "                                                                     OneHotEncoder(categorie...\n",
       "                                 feature_types=None, gamma=None, grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=0.20758583309417156, max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=26,\n",
       "                                 max_leaves=None, min_child_weight=None,\n",
       "                                 missing=nan, monotone_constraints=None,\n",
       "                                 multi_strategy=None, n_estimators=57,\n",
       "                                 n_jobs=None, num_parallel_tree=None,\n",
       "                                 random_state=None, ...))])},\n",
       " 'misc': {'tid': 10,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'learning_rate': [10],\n",
       "   'max_depth': [10],\n",
       "   'n_estimators': [10],\n",
       "   'seed': [10],\n",
       "   'subsample': [10]},\n",
       "  'vals': {'learning_rate': [0.20758583309417156],\n",
       "   'max_depth': [25],\n",
       "   'n_estimators': [56],\n",
       "   'seed': [1],\n",
       "   'subsample': [0.5460993371508303]}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2024, 11, 5, 23, 53, 51, 168000),\n",
       " 'refresh_time': datetime.datetime(2024, 11, 5, 23, 54, 0, 474000)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialsXGBoost.trials[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_XGB_df = pd.DataFrame.from_dict(xgbValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>subsample</th>\n",
       "      <th>seed</th>\n",
       "      <th>falsePositive</th>\n",
       "      <th>i</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>163</td>\n",
       "      <td>1.173579</td>\n",
       "      <td>1.867897</td>\n",
       "      <td>3</td>\n",
       "      <td>0.337362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.664471</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.047546</td>\n",
       "      <td>0.833664</td>\n",
       "      <td>0.833664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1.089087</td>\n",
       "      <td>1.935710</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387473</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265316</td>\n",
       "      <td>0.614854</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.041676</td>\n",
       "      <td>0.826050</td>\n",
       "      <td>0.826050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>172</td>\n",
       "      <td>1.173232</td>\n",
       "      <td>1.999207</td>\n",
       "      <td>2</td>\n",
       "      <td>0.372762</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.629420</td>\n",
       "      <td>0.022187</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.823335</td>\n",
       "      <td>0.823335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>1.080891</td>\n",
       "      <td>1.942103</td>\n",
       "      <td>3</td>\n",
       "      <td>0.267235</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250335</td>\n",
       "      <td>0.733905</td>\n",
       "      <td>0.030680</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.059218</td>\n",
       "      <td>0.878320</td>\n",
       "      <td>0.878320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>1.284513</td>\n",
       "      <td>1.882644</td>\n",
       "      <td>3</td>\n",
       "      <td>0.262514</td>\n",
       "      <td>4</td>\n",
       "      <td>0.154030</td>\n",
       "      <td>0.738580</td>\n",
       "      <td>0.031214</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.060213</td>\n",
       "      <td>0.876990</td>\n",
       "      <td>0.876990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "      <td>1.070433</td>\n",
       "      <td>1.569413</td>\n",
       "      <td>2</td>\n",
       "      <td>0.245394</td>\n",
       "      <td>995</td>\n",
       "      <td>0.384214</td>\n",
       "      <td>0.755582</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.064133</td>\n",
       "      <td>0.890840</td>\n",
       "      <td>0.890840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>16</td>\n",
       "      <td>189</td>\n",
       "      <td>1.033319</td>\n",
       "      <td>1.676919</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343268</td>\n",
       "      <td>996</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>0.658623</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>0.845447</td>\n",
       "      <td>0.845447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>1.020452</td>\n",
       "      <td>1.751205</td>\n",
       "      <td>2</td>\n",
       "      <td>0.238697</td>\n",
       "      <td>997</td>\n",
       "      <td>0.420887</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.034337</td>\n",
       "      <td>0.846435</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.890908</td>\n",
       "      <td>0.890908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>1.039398</td>\n",
       "      <td>1.639796</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313624</td>\n",
       "      <td>998</td>\n",
       "      <td>0.273289</td>\n",
       "      <td>0.688043</td>\n",
       "      <td>0.026267</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>0.867825</td>\n",
       "      <td>0.867825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "      <td>1.051876</td>\n",
       "      <td>1.554713</td>\n",
       "      <td>2</td>\n",
       "      <td>0.314266</td>\n",
       "      <td>999</td>\n",
       "      <td>0.019769</td>\n",
       "      <td>0.687339</td>\n",
       "      <td>0.026209</td>\n",
       "      <td>0.848263</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.853031</td>\n",
       "      <td>0.853031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  n_estimators  learning_rate  subsample  seed  falsePositive  \\\n",
       "0           16           163       1.173579   1.867897     3       0.337362   \n",
       "1           10            12       1.089087   1.935710     1       0.387473   \n",
       "2           15           172       1.173232   1.999207     2       0.372762   \n",
       "3            4            92       1.080891   1.942103     3       0.267235   \n",
       "4            2           150       1.284513   1.882644     3       0.262514   \n",
       "..         ...           ...            ...        ...   ...            ...   \n",
       "995          1           197       1.070433   1.569413     2       0.245394   \n",
       "996         16           189       1.033319   1.676919     2       0.343268   \n",
       "997          2           124       1.020452   1.751205     2       0.238697   \n",
       "998          7            47       1.039398   1.639796     1       0.313624   \n",
       "999         18           114       1.051876   1.554713     2       0.314266   \n",
       "\n",
       "       i  threshold  accuracy  precision    recall        f1       auc  \\\n",
       "0      0   0.001433  0.664471   0.024458  0.848263  0.047546  0.833664   \n",
       "1      1   0.265316  0.614854   0.021363  0.848263  0.041676  0.826050   \n",
       "2      2   0.001815  0.629420   0.022187  0.848263  0.043243  0.823335   \n",
       "3      3   0.250335  0.733905   0.030680  0.848263  0.059218  0.878320   \n",
       "4      4   0.154030  0.738580   0.031214  0.848263  0.060213  0.876990   \n",
       "..   ...        ...       ...        ...       ...       ...       ...   \n",
       "995  995   0.384214  0.755582   0.033326  0.848263  0.064133  0.890840   \n",
       "996  996   0.020023  0.658623   0.024048  0.848263  0.046769  0.845447   \n",
       "997  997   0.420887  0.763469   0.034337  0.846435  0.065997  0.890908   \n",
       "998  998   0.273289  0.688043   0.026267  0.848263  0.050955  0.867825   \n",
       "999  999   0.019769  0.687339   0.026209  0.848263  0.050847  0.853031   \n",
       "\n",
       "         auc2  \n",
       "0    0.833664  \n",
       "1    0.826050  \n",
       "2    0.823335  \n",
       "3    0.878320  \n",
       "4    0.876990  \n",
       "..        ...  \n",
       "995  0.890840  \n",
       "996  0.845447  \n",
       "997  0.890908  \n",
       "998  0.867825  \n",
       "999  0.853031  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_XGB_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceihml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
